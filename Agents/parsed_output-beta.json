[
  {
    "type": "markdown",
    "content": "Problem Statement\n\u00b6"
  },
  {
    "type": "markdown",
    "content": "Business Context\n\u00b6"
  },
  {
    "type": "markdown",
    "content": "Business communities in the United States are facing high demand for human resources, but one of the constant challenges is identifying and attracting the right talent, which is perhaps the most important element in remaining competitive. Companies in the United States look for hard-working, talented, and qualified individuals both locally as well as abroad.\nThe Immigration and Nationality Act (INA) of the US permits foreign workers to come to the United States to work on either a temporary or permanent basis. The act also protects US workers against adverse impacts on their wages or working conditions by ensuring US employers' compliance with statutory requirements when they hire foreign workers to fill workforce shortages. The immigration programs are administered by the Office of Foreign Labor Certification (OFLC).\nOFLC processes job certification applications for employers seeking to bring foreign workers into the United States and grants certifications in those cases where employers can demonstrate that there are not sufficient US workers available to perform the work at wages that meet or exceed the wage paid for the occupation in the area of intended employment."
  },
  {
    "type": "markdown",
    "content": "Objective\n\u00b6"
  },
  {
    "type": "markdown",
    "content": "In FY 2016, the OFLC processed 775,979 employer applications for 1,699,957 positions for temporary and permanent labor certifications. This was a nine percent increase in the overall number of processed applications from the previous year.\nThe process of reviewing every case is becoming a tedious task as the number of applicants is increasing every year.\nThe increasing number of applicants every year calls for a Machine Learning based solution that can help in shortlisting the candidates having higher chances of VISA approval. OFLC has hired the firm EasyVisa for data-driven solutions. You as a data  scientist at EasyVisa have to analyze the data provided and, with the help of a\nclassification model\n:\nFacilitate the process of visa approvals.\nRecommend a suitable profile for the applicants for whom the visa should be certified or denied based on the drivers that significantly influence the case status."
  },
  {
    "type": "markdown",
    "content": "Data Description\n\u00b6"
  },
  {
    "type": "markdown",
    "content": "The detailed data dictionary is given below:\ncase_id\n: ID of each visa application\ncontinent\n: Continent where the employee resides\neducation_of_employee\n: Information of education of the employee\nhas_job_experience\n: Does the employee have any job experience? Y= Yes; N = No\nrequires_job_training\n: Does the employee require any job training? Y = Yes; N = No\nno_of_employees\n: Number of employees in the employer's company\nyr_of_estab\n: Year in which the employer's company was established\nregion_of_employment\n: Information of foreign worker's intended region of employment in the US.\nprevailing_wage\n: Average wage paid to similarly employed workers in a specific occupation in the area of intended employment. The purpose of the prevailing wage is to ensure that the foreign worker is not underpaid compared to other workers offering the same or similar service in the same area of employment.\nunit_of_wage\n: Unit of prevailing wage. Values include Hourly, Weekly, Monthly, and Yearly.\nfull_time_position\n: Is the position of work full-time? Y = Full Time Position; N = Part Time Position\ncase_status\n:  Flag indicating if the Visa was certified or denied"
  },
  {
    "type": "markdown",
    "content": "Installing and Importing Necessary Libraries\n\u00b6"
  },
  {
    "type": "code",
    "code": "# Installing the libraries with the specified version.\n!pip install numpy==1.25.2 pandas==1.5.3 scikit-learn==1.5.2 matplotlib==3.7.1 seaborn==0.13.1 xgboost==2.0.3 -q --user",
    "output": "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).",
    "image_path": null
  },
  {
    "type": "code",
    "code": "import warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Libraries to help with reading and manipulating data\nimport numpy as np\nimport pandas as pd\n\n# Library to split data\nfrom sklearn.model_selection import train_test_split\n\n# To oversample and undersample data\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n\n# Libaries to help with data visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Removes the limit for the number of displayed columns\npd.set_option(\"display.max_columns\", None)\n# Sets the limit for the number of displayed rows\npd.set_option(\"display.max_rows\", 100)\n\n# Libraries for different ensemble classifiers\nfrom sklearn.ensemble import (\n    BaggingClassifier,\n    RandomForestClassifier,\n    AdaBoostClassifier,\n    GradientBoostingClassifier\n)\nfrom xgboost import XGBClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n\n# Libraries to get different metric scores\nfrom sklearn import metrics\nfrom sklearn.metrics import (\n    confusion_matrix,\n    accuracy_score,\n    precision_score,\n    recall_score,\n    f1_score,\n)\n# To tune different models\nfrom sklearn.model_selection import RandomizedSearchCV",
    "output": "   Unnamed: 0 case_id continent education_of_employee has_job_experience requires_job_training  no_of_employees  yr_of_estab region_of_employment  prevailing_wage unit_of_wage full_time_position case_status\n0           0  EZYV01      Asia           High School                  N                     N            14513         2007                 West         592.2029         Hour                  Y      Denied\n1           1  EZYV02      Asia              Master's                  Y                     N             2412         2002            Northeast       83425.6500         Year                  Y   Certified\n2           2  EZYV03      Asia            Bachelor's                  N                     Y            44444         2008                 West      122996.8600         Year                  Y      Denied\n3           3  EZYV04      Asia            Bachelor's                  N                     N               98         1897                 West       83434.0300         Year                  Y      Denied\n4           4  EZYV05    Africa              Master's                  Y                     N             1082         2005                South      149907.3900         Year                  Y   Certified",
    "image_path": null
  },
  {
    "type": "markdown",
    "content": "Import Dataset\n\u00b6"
  },
  {
    "type": "code",
    "code": "# Mount Google Drive\nfrom google.colab import drive\ndrive.mount('/content/drive')",
    "output": "   Unnamed: 0    case_id continent education_of_employee has_job_experience requires_job_training  no_of_employees  yr_of_estab region_of_employment  prevailing_wage unit_of_wage full_time_position case_status\n0       25475  EZYV25476      Asia            Bachelor's                  Y                     Y             2601         2008                South         77092.57         Year                  Y   Certified\n1       25476  EZYV25477      Asia           High School                  Y                     N             3274         2006            Northeast        279174.79         Year                  Y   Certified\n2       25477  EZYV25478      Asia              Master's                  Y                     N             1121         1910                South        146298.85         Year                  N   Certified\n3       25478  EZYV25479      Asia              Master's                  Y                     Y             1918         1887                 West         86154.77         Year                  Y   Certified\n4       25479  EZYV25480      Asia            Bachelor's                  Y                     N             3195         1960              Midwest         70876.91         Year                  Y   Certified",
    "image_path": null
  },
  {
    "type": "code",
    "code": "# Select Dataset\nvisa = pd.read_csv('/content/drive/MyDrive/AIML Course/Module 3 - Advanced Machine Learning/Project/EasyVisa.csv')",
    "output": "(25480, 12)",
    "image_path": null
  },
  {
    "type": "code",
    "code": "# Copying data to another variable to avoid any changes to original data\ndata = visa.copy()",
    "output": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 25480 entries, 0 to 25479\nData columns (total 12 columns):\n #   Column                 Non-Null Count  Dtype  \n---  ------                 --------------  -----  \n 0   case_id                25480 non-null  object \n 1   continent              25480 non-null  object \n 2   education_of_employee  25480 non-null  object \n 3   has_job_experience     25480 non-null  object \n 4   requires_job_training  25480 non-null  object \n 5   no_of_employees        25480 non-null  int64  \n 6   yr_of_estab            25480 non-null  int64  \n 7   region_of_employment   25480 non-null  object \n 8   prevailing_wage        25480 non-null  float64\n 9   unit_of_wage           25480 non-null  object \n 10  full_time_position     25480 non-null  object \n 11  case_status            25480 non-null  object \ndtypes: float64(1), int64(2), object(9)\nmemory usage: 2.3+ MB",
    "image_path": null
  },
  {
    "type": "markdown",
    "content": "Overview of the Dataset\n\u00b6"
  },
  {
    "type": "markdown",
    "content": "View the first and last 5 rows of the dataset\n\u00b6"
  },
  {
    "type": "code",
    "code": "## View top 5 rows of the data\ndata.head()",
    "output": "0",
    "image_path": null
  },
  {
    "type": "code",
    "code": "## View last 5 rows of the data\ndata.tail()",
    "output": "  Unnamed: 0  no_of_employees   yr_of_estab  prevailing_wage\n0      count     25480.000000  25480.000000     25480.000000\n1       mean      5667.043210   1979.409929     74455.814592\n2        std     22877.928848     42.366929     52815.942327\n3        min       -26.000000   1800.000000         2.136700\n4        25%      1022.000000   1976.000000     34015.480000",
    "image_path": null
  },
  {
    "type": "markdown",
    "content": "Initial Feature Observations\n\u00b6\nBased on a quick scan of the dataset, there are both categorical and numerical features, making this a classification problem well-suited to tree-based models.\nTarget Variable:\ncase_status\n(Certified vs. Denied)\n8 Categorical Features:\ncontinent\n,\neducation_of_employee\n,\nhas_job_experience\n,\nrequires_job_training\n,\nunit_of_wage\n,\nregion_of_employment\n,\nfull_time_position\n, and\ncase_status\n3 Numerical Features:\nprevailing_wage\n,\nno_of_employees\n,\nyr_of_estab\n4 Binary Variables:\ncase_status\n,\nfull_time_position\n,\nhas_job_experience\n,\nrequires_job_training\nBinary variables will be mapped to 0/1 during pre-processing.\nThe\nprevailing_wage\ncolumn needs\nnormalization\nsince\nunit_of_wage\nincludes values like Hourly, Weekly, Monthly, and Yearly.\nThere's a wide range of values in both\nno_of_employees\nand\nyr_of_estab\nwhich could be explored during EDA.\ncase_id\nis a unique identifier and will be excluded from modeling."
  },
  {
    "type": "markdown",
    "content": "Understand the Shape of the Dataset\n\u00b6"
  },
  {
    "type": "code",
    "code": "## View dimensions of the data (rows, columns)\ndata.shape",
    "output": "(33, 12)",
    "image_path": null
  },
  {
    "type": "markdown",
    "content": "Check the Column Data Types\n\u00b6"
  },
  {
    "type": "code",
    "code": "# View the column data types\ndata.info()",
    "output": "EZYV01       1\nEZYV16995    1\nEZYV16993    1\nEZYV16992    1\nEZYV16991    1\n            ..\nEZYV8492     1\nEZYV8491     1\nEZYV8490     1\nEZYV8489     1\nEZYV25480    1\nName: case_id, Length: 25480, dtype: int64\n--------------------------------------------------\nAsia             16861\nEurope            3732\nNorth America     3292\nSouth America      852\nAfrica             551\nOceania            192\nName: continent, dtype: int64\n--------------------------------------------------\nBachelor's     10234\nMaster's        9634\nHigh School     3420\nDoctorate       2192\nName: education_of_employee, dtype: int64\n--------------------------------------------------\nY    14802\nN    10678\nName: has_job_experience, dtype: int64\n--------------------------------------------------\nN    22525\nY     2955\nName: requires_job_training, dtype: int64\n--------------------------------------------------\nNortheast    7195\nSouth        7017\nWest         6586\nMidwest      4307\nIsland        375\nName: region_of_employment, dtype: int64\n--------------------------------------------------\nYear     22962\nHour      2157\nWeek       272\nMonth       89\nName: unit_of_wage, dtype: int64\n--------------------------------------------------\nY    22773\nN     2707\nName: full_time_position, dtype: int64\n--------------------------------------------------\nCertified    17018\nDenied        8462\nName: case_status, dtype: int64\n--------------------------------------------------",
    "image_path": null
  },
  {
    "type": "code",
    "code": "# Check for duplicate entries in the data\ndata.duplicated().sum()",
    "output": "25480",
    "image_path": null
  },
  {
    "type": "markdown",
    "content": "Is the Data Ready For EDA? - Yes\n\u00b6\nThe dataset has 25,480 rows and 12 columns.\nAll 12 columns are fully populated (25,480 entries), indicating there's no missing data.\nThere are no duplicate values.\nNo major data quality issues detected. No further imputation or treatment necessary. Ready to proceed with EDA, followed by data pre-processing."
  },
  {
    "type": "markdown",
    "content": "Exploratory Data Analysis (EDA)\n\u00b6"
  },
  {
    "type": "markdown",
    "content": "Statistical Summary of the Data\n\u00b6"
  },
  {
    "type": "code",
    "code": "# View statistical summary of dataset\ndata.describe()",
    "output": "",
    "image_path": "extracted_images_beta\\image_1.png"
  },
  {
    "type": "markdown",
    "content": "no_of_employees\nhas a wide range (from -26 to over 600,000), with a mean of 5,667 but a median of 2,109, suggesting a strong right-skewed distribution.\nyr_of_estab\nranges from 1800 to 2016 with a median of 1997, indicating many companies have been established for decades.\nprevailing_wage\nvaries greatly, from 2.14 to 319,210, with a median of 70,308 and a high standard deviation, indicating significant variance in wage levels."
  },
  {
    "type": "markdown",
    "content": "Fix Negative Number of Employees Values\n\u00b6"
  },
  {
    "type": "code",
    "code": "# Check for negative values in number of employees\ndata.loc[data['no_of_employees'] < 0].shape",
    "output": "",
    "image_path": "extracted_images_beta\\image_2.png"
  },
  {
    "type": "markdown",
    "content": "There are 33 rows where the\nno_of_employees\nvalue is negative."
  },
  {
    "type": "code",
    "code": "# Convert negative values to absolute\ndata[\"no_of_employees\"] = data[\"no_of_employees\"].apply(abs)",
    "output": "",
    "image_path": "extracted_images_beta\\image_3.png"
  },
  {
    "type": "markdown",
    "content": "This assumes the negative values were just data entry errors and the values should have been positive."
  },
  {
    "type": "markdown",
    "content": "Check Count of Unique Categories in Categorical Variables\n\u00b6"
  },
  {
    "type": "code",
    "code": "# Making a list of all categorical variables\ncat_col = list(data.select_dtypes(\"object\").columns)\nfor column in cat_col:\n    print(data[column].value_counts())\n    print(\"-\" * 50)",
    "output": "",
    "image_path": "extracted_images_beta\\image_4.png"
  },
  {
    "type": "markdown",
    "content": "Category Observations\n\u00b6\nLooking at the categorical features, I was able to confirm:\ncontinent\n: 66% of applicants are from Asia, followed by Europe and North America.\neducation_of_employee\n: Most hold a Bachelor's or Master's degree. Fewer have Doctorate or High School.\nhas_job_experience\n: ~60% have job experience, which may influence visa outcomes.\nrequires_job_training\n: Only ~12% require training, suggesting most are job-ready.\nregion_of_employment\n: Distributed across Northeast, South, and West, with fewer in Midwest and Island.\nunit_of_wage\n: 90% report wages as Yearly, 8% as Hourly, and few as Weekly or Monthly.\nfull_time_position\n: 89% are full-time, 11% part-time.\ncase_status\n: 67% are Certified, 33% Denied, showing class imbalance."
  },
  {
    "type": "code",
    "code": "# View umber of unique values in case_id\ndata[\"case_id\"].nunique()",
    "output": "",
    "image_path": "extracted_images_beta\\image_5.png"
  },
  {
    "type": "markdown",
    "content": "There are 25,480 unique\ncase_id\nvalues, which means this column is simply a row-level ID and can be dropped from the dataset, as it will not help predict\ncase_status\n."
  },
  {
    "type": "code",
    "code": "# Drop the 'case_id' column\ndata.drop([\"case_id\"], axis=1, inplace=True)",
    "output": "",
    "image_path": "extracted_images_beta\\image_6.png"
  },
  {
    "type": "markdown",
    "content": "Univariate Analysis\n\u00b6"
  },
  {
    "type": "code",
    "code": "# Function to create combined boxplot and histogram\n\ndef histogram_boxplot(data, feature, figsize=(10, 5), kde=False, bins=None):\n    \"\"\"\n    Boxplot and histogram combined with improved formatting\n\n    data: dataframe\n    feature: dataframe column\n    figsize: size of figure (default (10, 5))\n    kde: whether to show the density curve (default False)\n    bins: number of bins for histogram (default None)\n    \"\"\"\n    f2, (ax_box2, ax_hist2) = plt.subplots(\n        nrows=2,\n        sharex=True,\n        gridspec_kw={\"height_ratios\": (0.25, 0.75)},\n        figsize=figsize,\n    )\n\n    # Boxplot\n    sns.boxplot(data=data, x=feature, ax=ax_box2, showmeans=True, color=\"violet\")\n    ax_box2.set_xlabel(feature, fontsize=12)  # Show label\n    ax_box2.set_title(f\"Distribution of {feature}\", fontsize=14)\n    ax_box2.tick_params(labelbottom=True)  # Enable x-axis tick labels on boxplot\n\n    # Histogram\n    if bins:\n        sns.histplot(data=data, x=feature, kde=kde, ax=ax_hist2, bins=bins)\n    else:\n        sns.histplot(data=data, x=feature, kde=kde, ax=ax_hist2)\n\n    # Add mean and median lines\n    ax_hist2.axvline(data[feature].mean(), color=\"green\", linestyle=\"--\", label=\"Mean\")\n    ax_hist2.axvline(data[feature].median(), color=\"black\", linestyle=\"-\", label=\"Median\")\n\n    # Add axis labels and legend\n    ax_hist2.set_xlabel(feature, fontsize=12)\n    ax_hist2.set_ylabel(\"Count\", fontsize=12)\n    ax_hist2.legend()\n\n    plt.tight_layout()\n    plt.show()",
    "output": "",
    "image_path": "extracted_images_beta\\image_7.png"
  },
  {
    "type": "code",
    "code": "# Function to create labeled barplots\n\ndef labeled_barplot(data, feature, perc=False, n=None):\n    \"\"\"\n    Barplot with percentage at the top\n\n    data: dataframe\n    feature: dataframe column\n    perc: whether to display percentages instead of count (default is False)\n    n: displays the top n category levels (default is None, i.e., display all levels)\n    \"\"\"\n\n    total = len(data[feature])  # length of the column\n    count = data[feature].nunique()\n    if n is None:\n        plt.figure(figsize=(count + 1, 5))\n    else:\n        plt.figure(figsize=(n + 1, 5))\n\n    plt.xticks(rotation=45, fontsize=15)\n    ax = sns.countplot(\n        data=data,\n        x=feature,\n        palette=\"Paired\",\n        order=data[feature].value_counts().index[:n].sort_values(),\n    )\n\n    for p in ax.patches:\n        if perc == True:\n            label = \"{:.1f}%\".format(\n                100 * p.get_height() / total\n            )  # percentage of each class of the category\n        else:\n            label = p.get_height()  # count of each level of the category\n\n        x = p.get_x() + p.get_width() / 2  # width of the plot\n        y = p.get_height()  # height of the plot\n\n        ax.annotate(\n            label,\n            (x, y),\n            ha=\"center\",\n            va=\"center\",\n            size=12,\n            xytext=(0, 5),\n            textcoords=\"offset points\",\n        )  # annotate the percentage\n\n    plt.show()  # show the plot",
    "output": "",
    "image_path": "extracted_images_beta\\image_8.png"
  },
  {
    "type": "markdown",
    "content": "Observations on Number of Employees\n\u00b6"
  },
  {
    "type": "code",
    "code": "# Distribution of number of employees\nhistogram_boxplot(data, \"no_of_employees\", kde=True, bins=50)",
    "output": "case_status            Certified  Denied    All\neducation_of_employee                          \nAll                        17018    8462  25480\nBachelor's                  6367    3867  10234\nHigh School                 1164    2256   3420\nMaster's                    7575    2059   9634\nDoctorate                   1912     280   2192\n------------------------------------------------------------------------------------------------------------------------",
    "image_path": null
  },
  {
    "type": "markdown",
    "content": "The distribution is heavily right-skewed, with most values under 10,000 and a long tail of extreme outliers.\nMean and median are both near zero, indicating most companies are small to mid-sized.\nThe boxplot confirms many outliers, with some companies reporting over 600,000 employees.\nThis skew may affect model performance and could require outlier handling."
  },
  {
    "type": "markdown",
    "content": "Observations on Prevailing Wage\n\u00b6"
  },
  {
    "type": "code",
    "code": "# Distribution of prevailing wage\nhistogram_boxplot(data, \"prevailing_wage\", kde=True, bins=50)",
    "output": "case_status    Certified  Denied    All\ncontinent                              \nAll                17018    8462  25480\nAsia               11012    5849  16861\nNorth America       2037    1255   3292\nEurope              2957     775   3732\nSouth America        493     359    852\nAfrica               397     154    551\nOceania              122      70    192\n------------------------------------------------------------------------------------------------------------------------",
    "image_path": null
  },
  {
    "type": "markdown",
    "content": "The distribution is right-skewed, with most wages under 100,000.\nThe mean is pulled up by high-wage outliers, while the median remains lower.\nThe boxplot shows many outliers above 200,000.\nA spike near zero may reflect unnormalized hourly wages and needs review."
  },
  {
    "type": "markdown",
    "content": "Observations on Year of Establishment\n\u00b6"
  },
  {
    "type": "code",
    "code": "# Distribution of year of establishment\nhistogram_boxplot(data, \"yr_of_estab\", kde=False)",
    "output": "case_status         Certified  Denied    All\nhas_job_experience                          \nAll                     17018    8462  25480\nN                        5994    4684  10678\nY                       11024    3778  14802\n------------------------------------------------------------------------------------------------------------------------",
    "image_path": null
  },
  {
    "type": "markdown",
    "content": "Most companies were established after 1980, with a spike in the early 2000s.\nA substantial number of older companies exist, especially before 1950, appearing as outliers on the lower end.\nThe mean is slightly lower than the median, pulled left by these older values.\nWhile the feature is usable, very early entries (e.g., 1800s) may be irrelevant for modern visa application behaviors."
  },
  {
    "type": "markdown",
    "content": "Observations on Education of Employee\n\u00b6"
  },
  {
    "type": "code",
    "code": "labeled_barplot(data, \"education_of_employee\", perc=True)",
    "output": "",
    "image_path": "extracted_images_beta\\image_9.png"
  },
  {
    "type": "markdown",
    "content": "The majority of applicants hold either a Bachelor\u2019s degree (40.2%) or a Master\u2019s degree (37.8%), together accounting for nearly 80% of the total.\nOnly 13.4% of applicants have a High School education, and just 8.6% hold a Doctorate.\nThe distribution suggests the visa applicant pool is generally well-educated, with a strong concentration in mid-to-advanced academic qualifications.\nThe bar plot suggests that most visa-sponsored jobs may not require PhDs."
  },
  {
    "type": "markdown",
    "content": "Observations on Region of Employment\n\u00b6"
  },
  {
    "type": "code",
    "code": "# Observations on region of employment\nlabeled_barplot(data, \"region_of_employment\", perc=True)",
    "output": "",
    "image_path": "extracted_images_beta\\image_10.png"
  },
  {
    "type": "markdown",
    "content": "The majority of applicants seek employment in the Northeast (28.2%), South (27.5%), and West (25.8%) regions.\nThe Midwest accounts for 16.9% of applications, making it the smallest among mainland regions.\nThe Island region represents just 1.5% of applications, indicating limited demand in U.S. territories."
  },
  {
    "type": "markdown",
    "content": "Observations on Job Experience\n\u00b6"
  },
  {
    "type": "code",
    "code": "# Observations on job experience\nlabeled_barplot(data, \"has_job_experience\", perc=True)",
    "output": "case_status   Certified  Denied    All\nunit_of_wage                          \nAll               17018    8462  25480\nYear              16047    6915  22962\nHour                747    1410   2157\nWeek                169     103    272\nMonth                55      34     89\n------------------------------------------------------------------------------------------------------------------------",
    "image_path": null
  },
  {
    "type": "markdown",
    "content": "The majority of applicants have prior job experience (58.1%), while 41.9% do not."
  },
  {
    "type": "markdown",
    "content": "Observations on Case Status\n\u00b6"
  },
  {
    "type": "code",
    "code": "# Observations on case status\nlabeled_barplot(data, \"case_status\", perc=True)",
    "output": "",
    "image_path": "extracted_images_beta\\image_11.png"
  },
  {
    "type": "markdown",
    "content": "The majority of visa applications are Certified (66.8%), while 33.2% are Denied.\nAlthough not severely imbalanced, the difference in class sizes suggests a moderate class imbalance.\nThis should be addressed during model training to ensure the model does not become biased toward the majority class."
  },
  {
    "type": "markdown",
    "content": "Bivariate Analysis\n\u00b6"
  },
  {
    "type": "code",
    "code": "# View relationships between variables\ncols_list = data.select_dtypes(include=np.number).columns.tolist()\n\nplt.figure(figsize=(10, 5))\nsns.heatmap(\n    data[cols_list].corr(),\n    annot=True,\n    vmin=-1,\n    vmax=1,\n    fmt=\".2f\",\n    cmap=\"Spectral\"\n)\nplt.show()",
    "output": "Shape of Training set :  (17836, 18)\nShape of Validation set :  (6879, 18)\nShape of test set :  (765, 18)\nPercentage of classes in training set:\n1    0.667919\n0    0.332081\nName: case_status, dtype: float64\nPercentage of classes in validation set:\n1    0.66783\n0    0.33217\nName: case_status, dtype: float64\nPercentage of classes in test set:\n1    0.667974\n0    0.332026\nName: case_status, dtype: float64",
    "image_path": null
  },
  {
    "type": "markdown",
    "content": "There is no strong correlation between any pair of numerical features, which reduces the risk of multicollinearity during modeling.\nno_of_employees\nshows a very weak negative correlation with both\nyr_of_estab\n(-0.02) and\nprevailing_wage\n(-0.01).\nyr_of_estab\nand\nprevailing_wage\nare also nearly uncorrelated (0.01)."
  },
  {
    "type": "markdown",
    "content": "Creating functions that will help us with further analysis."
  },
  {
    "type": "code",
    "code": "# Function to plot distributions with regard to target\n\ndef distribution_plot_wrt_target(data, predictor, target):\n\n    fig, axs = plt.subplots(2, 2, figsize=(12, 10))\n\n    target_uniq = data[target].unique()\n\n    axs[0, 0].set_title(\"Distribution of target for target=\" + str(target_uniq[0]))\n    sns.histplot(\n        data=data[data[target] == target_uniq[0]],\n        x=predictor,\n        kde=True,\n        ax=axs[0, 0],\n        color=\"teal\",\n        stat=\"density\",\n    )\n\n    axs[0, 1].set_title(\"Distribution of target for target=\" + str(target_uniq[1]))\n    sns.histplot(\n        data=data[data[target] == target_uniq[1]],\n        x=predictor,\n        kde=True,\n        ax=axs[0, 1],\n        color=\"orange\",\n        stat=\"density\",\n    )\n\n    axs[1, 0].set_title(\"Boxplot w.r.t target\")\n    sns.boxplot(data=data, x=target, y=predictor, ax=axs[1, 0], palette=\"gist_rainbow\")\n\n    axs[1, 1].set_title(\"Boxplot (without outliers) w.r.t target\")\n    sns.boxplot(\n        data=data,\n        x=target,\n        y=predictor,\n        ax=axs[1, 1],\n        showfliers=False,\n        palette=\"gist_rainbow\",\n    )\n\n    plt.tight_layout()\n    plt.show()",
    "output": "   Unnamed: 0  has_job_experience  requires_job_training  no_of_employees  yr_of_estab  full_time_position  normalized_wage  continent_Asia  continent_Europe  continent_North America  continent_Oceania  continent_South America  education_of_employee_Doctorate  education_of_employee_High School  education_of_employee_Master's  region_of_employment_Midwest  region_of_employment_Northeast  region_of_employment_South  region_of_employment_West\n0           0                   0                      0            14513         2007                   1      1231782.032               1                 0                        0                  0                        0                                0                                  1                               0                             0                               0                           0                          1\n1           1                   1                      0             2412         2002                   1        83425.650               1                 0                        0                  0                        0                                0                                  0                               1                             0                               1                           0                          0\n2           2                   0                      1            44444         2008                   1       122996.860               1                 0                        0                  0                        0                                0                                  0                               0                             0                               0                           0                          1\n3           3                   0                      0               98         1897                   1        83434.030               1                 0                        0                  0                        0                                0                                  0                               0                             0                               0                           0                          1\n4           4                   1                      0             1082         2005                   1       149907.390               0                 0                        0                  0                        0                                0                                  0                               1                             0                               0                           1                          0",
    "image_path": null
  },
  {
    "type": "code",
    "code": "# Function to create stacked barplot\n\ndef stacked_barplot(data, predictor, target):\n    \"\"\"\n    Print the category counts and plot a stacked bar chart\n\n    data: dataframe\n    predictor: independent variable\n    target: target variable\n    \"\"\"\n    count = data[predictor].nunique()\n    sorter = data[target].value_counts().index[-1]\n    tab1 = pd.crosstab(data[predictor], data[target], margins=True).sort_values(\n        by=sorter, ascending=False\n    )\n    print(tab1)\n    print(\"-\" * 120)\n    tab = pd.crosstab(data[predictor], data[target], normalize=\"index\").sort_values(\n        by=sorter, ascending=False\n    )\n    tab.plot(kind=\"bar\", stacked=True, figsize=(count + 5, 5))\n    plt.legend(\n        loc=\"lower left\", frameon=False,\n    )\n    plt.legend(loc=\"upper left\", bbox_to_anchor=(1, 1))\n    plt.show()",
    "output": "Cross-Validation Performance on Training Dataset:\n\nBagging: 0.7737683500847006\nRandom forest: 0.8002763453794746\nGBM: 0.819460827255206\nAdaboost: 0.8155205845647009\nXgboost: 0.8071535268739292\ndtree: 0.7381787312216336\n\nValidation Performance:\n\nBagging: 0.7641622268130912\nRandom forest: 0.7959929041010122\nGBM: 0.8139201637666326\nAdaboost: 0.8123872519542995\nXgboost: 0.8017384105960265\ndtree: 0.7307734624271097",
    "image_path": null
  },
  {
    "type": "markdown",
    "content": "Case Status by Education of Employee\n\u00b6"
  },
  {
    "type": "code",
    "code": "stacked_barplot(data, \"education_of_employee\", \"case_status\")",
    "output": "",
    "image_path": "extracted_images_beta\\image_12.png"
  },
  {
    "type": "markdown",
    "content": "High school applicants face the highest denial rate, suggesting education plays a strong role in visa approval likelihood.\nThe trend is clearly upward, supporting the idea that more advanced qualifications may strengthen a candidate's application."
  },
  {
    "type": "markdown",
    "content": "Case Status by Continent\n\u00b6"
  },
  {
    "type": "code",
    "code": "# Continent vs. case status\nstacked_barplot(data, \"continent\", \"case_status\")",
    "output": "Before OverSampling, counts of label '1': 11913\nBefore OverSampling, counts of label '0': 5923 \n\nAfter OverSampling, counts of label '1': 11913\nAfter OverSampling, counts of label '0': 11913 \n\nAfter OverSampling, the shape of train_X: (23826, 18)\nAfter OverSampling, the shape of train_y: (23826,)",
    "image_path": null
  },
  {
    "type": "markdown",
    "content": "Europe has the highest certification rate (79%), followed by Africa (72%) and Asia (66%).\nSouth America and North America have the lowest certification rates, below 60%.\nOceania shows moderate certification rates (64%), though the sample size is small.\nOverall, visa approval likelihood appears to vary by continent, but sample size differences (e.g., low counts in Africa and Oceania) may influence interpretation."
  },
  {
    "type": "markdown",
    "content": "Case Status by Job Experience\n\u00b6"
  },
  {
    "type": "code",
    "code": "# Job experience vs. case status\nstacked_barplot(data, \"has_job_experience\", \"case_status\")",
    "output": "Cross-Validation Performance on Training Dataset:\n\nBagging: 0.7623811470534795\nRandom forest: 0.7884560746689021\nGBM: 0.795876758865492\nAdaboost: 0.780751339379742\nXgboost: 0.7936226748593003\ndtree: 0.7287896417795261\n\nValidation Performance:\n\nBagging: 0.7527839643652561\nRandom forest: 0.7835669198673371\nGBM: 0.7966573816155988\nAdaboost: 0.7781664016958134\nXgboost: 0.790594216714331\ndtree: 0.7305521743941573",
    "image_path": null
  },
  {
    "type": "markdown",
    "content": "Applicants with job experience (Y) have a higher certification rate (74%) compared to those without experience (N) (56%).\nLack of job experience is associated with a higher denial rate.\nThis suggests that prior work experience may positively influence visa approval outcomes."
  },
  {
    "type": "markdown",
    "content": "Prevailing Wage by U.S. Region\n\u00b6"
  },
  {
    "type": "code",
    "code": "# Prevailing wage across regions\nplt.figure(figsize=(10, 5))\nsns.boxplot(data=data, x=\"region_of_employment\", y=\"prevailing_wage\")\nplt.show()",
    "output": "",
    "image_path": "extracted_images_beta\\image_13.png"
  },
  {
    "type": "markdown",
    "content": "Median wages are fairly consistent across most regions, especially between West, Northeast, and South.\nThe Midwest and Island regions show slightly higher median wages compared to others.\nAll regions exhibit a large number of high-wage outliers, indicating similar wage variance nationwide.\nOverall, regional differences in prevailing wage are minor, suggesting location may not be a strong predictor of wage in this dataset."
  },
  {
    "type": "markdown",
    "content": "Case Status by Prevailing Wage\n\u00b6"
  },
  {
    "type": "code",
    "code": "# Distribution of prevailing wage by case status\ndistribution_plot_wrt_target(data, \"prevailing_wage\", \"case_status\")",
    "output": "Before UnderSampling, counts of label '1': 11913\nBefore UnderSampling, counts of label '0': 5923 \n\nAfter UnderSampling, counts of label '1': 5923\nAfter UnderSampling, counts of label '0': 5923 \n\nAfter UnderSampling, the shape of train_X: (11846, 18)\nAfter UnderSampling, the shape of train_y: (11846,)",
    "image_path": null
  },
  {
    "type": "markdown",
    "content": "Certified applications tend to have higher prevailing wages than Denied ones (visible in both the histogram and boxplot).\nThe median wage for Certified applicants is higher than for Denied applicants.\nDenied applications have more density in the lower wage range (especially < 40,000)\nOutliers are present in both categories, but more extreme values are seen in Certified cases."
  },
  {
    "type": "markdown",
    "content": "Case Status by Unit of Wage\n\u00b6"
  },
  {
    "type": "code",
    "code": "# Unit of wage vs. case status\nstacked_barplot(data, \"unit_of_wage\", \"case_status\")",
    "output": "Cross-Validation Performance on Training Dataset:\n\nBagging: 0.645496870856901\nRandom forest: 0.6825424389928453\nGBM: 0.7099017283532761\nAdaboost: 0.6967802055171848\nXgboost: 0.6881278799865752\ndtree: 0.6141423241712982\n\nValidation Performance:\n\nBagging: 0.6876325970298265\nRandom forest: 0.7302308888623041\nGBM: 0.7592570961336292\nAdaboost: 0.7532256189701267\nXgboost: 0.7416154936230515\ndtree: 0.6776195691858342",
    "image_path": null
  },
  {
    "type": "markdown",
    "content": "Applications with Yearly wages have the highest approval rate (~70% certified).\nThose with Hourly wages have the lowest approval rate, with more denials than approvals.\nWeekly and Monthly wages fall in between, with moderate approval rates.\nThis suggests that jobs offering annual salaries are more likely to be approved for visas."
  },
  {
    "type": "markdown",
    "content": "Summary of Bivariate Analysis:\n\u00b6\nNo strong correlations between numeric variables, meaning multicollinearity is not a concern for modeling.\nVisa approval rates increase with education level. Applicants with Master's and Doctorates are more likely to be certified than those with only a high school education.\nCertification rates vary by continent. Europe and Africa have the highest approval rates, while South and North America have the lowest.\nApplicants with prior work experience are significantly more likely to be certified than those without.\nPrevailing wages are fairly consistent across U.S. regions. Regional differences are small and likely not predictive.\nCertified applicants tend to have higher wages. Denied applications are more common in lower wage ranges (< 40K).\nApplicants with Yearly salaries are most likely to be certified. Hourly wage earners have the highest denial rates."
  },
  {
    "type": "markdown",
    "content": "Data Pre-Processing\n\u00b6"
  },
  {
    "type": "markdown",
    "content": "Outlier Check\n\u00b6"
  },
  {
    "type": "code",
    "code": "# outlier detection using boxplot\nnumeric_columns = data.select_dtypes(include=np.number).columns.tolist()\nplt.figure(figsize=(15, 12))\n\nfor i, variable in enumerate(numeric_columns):\n    plt.subplot(4, 4, i + 1)\n    plt.boxplot(data[variable], whis=1.5)\n    plt.tight_layout()\n    plt.title(variable)\n\nplt.show()",
    "output": "",
    "image_path": "extracted_images_beta\\image_14.png"
  },
  {
    "type": "markdown",
    "content": "Observations on Outliers\n\u00b6\nno_of_employees\nhas many extreme outliers, with values well above 100,000. Most data points are concentrated near the lower end.\nyr_of_estab\nshows a large cluster of older companies (pre-1950) that appear as lower-end outliers. Most companies were founded after 1980.\nprevailing_wage\nhas many high-wage outliers above 200K. The majority of values are concentrated below 100K.\nI chose not to remove outliers because I\u2019ll be using decision tree-based models, which are robust to outliers by design. Additionally, there are a significant number of upper outliers, and many of them may represent valid cases (e.g., large companies or high-paying roles), so I believe it\u2019s better to retain them rather than risk losing meaningful information."
  },
  {
    "type": "markdown",
    "content": "Data Preparation for Modeling\n\u00b6\nWe want to predict which visa will be certified.\nBefore creating a model, we need to\nnormalize the unit of wage to Yearly\n,\nconvert binary variables\n, and\nencode categorical features\n.\nWe'll split the data into train and test to be able to evaluate the model that we build on the train data."
  },
  {
    "type": "code",
    "code": "# Normalize unit_of_wage to Yearly\n\nconversion_factors = {\n    \"Hour\": 2080,   # 40 hours/week * 52 weeks\n    \"Week\": 52,     # 52 weeks/year\n    \"Month\": 12,    # 12 months/year\n    \"Year\": 1       # Already yearly\n}\n\n# Create new column, 'normalized_wage'\ndata[\"normalized_wage\"] = data.apply(\n    lambda row: row[\"prevailing_wage\"] * conversion_factors.get(row[\"unit_of_wage\"], 1),\n    axis=1\n)\n\n# Drop original 'prevailing_wage' and 'unit_of_wage' columns\ndata.drop([\"prevailing_wage\", \"unit_of_wage\"], axis=1, inplace=True)",
    "output": "Best parameters are {'n_estimators': 200, 'learning_rate': 0.1, 'estimator': DecisionTreeClassifier(max_depth=3, random_state=1)} with CV score=0.791770361085057\nCPU times: user 16.8 s, sys: 1.48 s, total: 18.2 s\nWall time: 13min 14s",
    "image_path": null
  },
  {
    "type": "markdown",
    "content": "This step normalizes\nunit_of_wage\ninto the same unit, Yearly."
  },
  {
    "type": "code",
    "code": "# Convert case_status to binary (Certified = 1, Denied = 0)\ndata[\"case_status\"] = data[\"case_status\"].apply(lambda x: 1 if x == \"Certified\" else 0)\n\n# Convert has_job_experience to binary (Yes = 1, No = 0)\ndata[\"has_job_experience\"] = data[\"has_job_experience\"].apply(lambda x: 1 if x == \"Y\" else 0)\n\n# Convert requires_job_training to binary (Yes = 1, No = 0)\ndata[\"requires_job_training\"] = data[\"requires_job_training\"].apply(lambda x: 1 if x == \"Y\" else 0)\n\n# Convert full_time_position to binary (Yes = 1, No = 0)\ndata[\"full_time_position\"] = data[\"full_time_position\"].apply(lambda x: 1 if x == \"Y\" else 0)\n\n# Drop case_status from feature set\nX = data.drop(\"case_status\", axis=1)\ny = data[\"case_status\"]\n\n# Create dummy variables for categorical columns\nX = pd.get_dummies(X, drop_first=True)\n\n# Split into train and validation sets (70% train, 30% val)\nX_train, X_val, y_train, y_val = train_test_split(\n    X, y, test_size=0.3, random_state=1, stratify=y\n)\n\n# Split validation set into validation and test (90% val, 10% test)\nX_val, X_test, y_val, y_test = train_test_split(\n    X_val, y_val, test_size=0.1, random_state=1, stratify=y_val\n)",
    "output": "AdaBoostClassifier(estimator=DecisionTreeClassifier(max_depth=3,\n                                                    random_state=1),\n                   learning_rate=0.1, n_estimators=200)",
    "image_path": null
  },
  {
    "type": "markdown",
    "content": "This step converts binary features into numerical features so they don't need dummy variables.\nIt also drops\ncase_status\nfrom the dataset, as it's our target variable.\nIt also utilizes one-hot encoding to create dummy variables for the remaining categorical features."
  },
  {
    "type": "code",
    "code": "print(\"Shape of Training set : \", X_train.shape)\nprint(\"Shape of Validation set : \", X_val.shape)\nprint(\"Shape of test set : \", X_test.shape)\nprint(\"Percentage of classes in training set:\")\nprint(y_train.value_counts(normalize=True))\nprint(\"Percentage of classes in validation set:\")\nprint(y_val.value_counts(normalize=True))\nprint(\"Percentage of classes in test set:\")\nprint(y_test.value_counts(normalize=True))",
    "output": "   Unnamed: 0  Accuracy    Recall  Precision        F1\n0           0  0.801729  0.818182   0.792117  0.804938",
    "image_path": null
  },
  {
    "type": "markdown",
    "content": "This step confirms the splitting of our dataset into train, test, and validation sets."
  },
  {
    "type": "code",
    "code": "X.head()",
    "output": "   Unnamed: 0  Accuracy    Recall  Precision        F1\n0           0  0.719872  0.807575    0.78056  0.793838",
    "image_path": null
  },
  {
    "type": "markdown",
    "content": "Data Pre-Processing Observations\n\u00b6\nI chose to convert features with Y/N values to binary numerical values (0/1) to reduce the number of columns created during one-hot encoding and keep the feature set simpler and more efficient for modeling.\nUsing the .head() method above, I verified that the binary conversions and one-hot encoding were successfully applied.\nI also confirmed that the normalized_wage column was added and the case_status target column was excluded from the feature set."
  },
  {
    "type": "markdown",
    "content": "Model Building\n\u00b6"
  },
  {
    "type": "markdown",
    "content": "Which Evaluation Metric Will I Use?:\n\u00b6\nThe business goal is to correctly\nidentify applicants who are likely to be certified\n, while\navoiding misclassification of those who should be denied\n.\nI'm choosing\nF1 Score\nas the primary evaluation metric because it balances both\nPrecision and Recall\n, which is important for this classification problem.\nFalse positives\n(certifying someone who should be denied) and\nfalse negatives\n(denying someone who could be certified) both have real-world consequences. A balanced metric like F1 Score helps address both.\nThere is also a\nmoderate class imbalance\nin the target variable (case_status), with about 67% of cases being Certified and 33% Denied.\nAccuracy alone could be misleading in this context."
  },
  {
    "type": "code",
    "code": "# Define function to compute performance metrics for classification model\n\ndef model_performance_classification_sklearn(model, predictors, target):\n    \"\"\"\n    Function to compute different metrics to check classification model performance\n\n    model: classifier\n    predictors: independent variables\n    target: dependent variable\n    \"\"\"\n\n    # Predict using independent variables\n    pred = model.predict(predictors)\n\n    acc = accuracy_score(target, pred)         # Compute Accuracy\n    recall = recall_score(target, pred)        # Compute Recall\n    precision = precision_score(target, pred)  # Compute Precision\n    f1 = f1_score(target, pred)                # Compute F1-score\n\n    # Creating dataframe of metrics\n    df_perf = pd.DataFrame(\n        {\"Accuracy\": acc, \"Recall\": recall, \"Precision\": precision, \"F1\": f1,},\n        index=[0],\n    )\n\n    return df_perf",
    "output": "Best parameters are {'n_estimators': 150, 'min_samples_leaf': 5, 'max_samples': 0.5, 'max_features': 'sqrt'} with CV score=0.7125902411652401:\nCPU times: user 3.13 s, sys: 293 ms, total: 3.42 s\nWall time: 2min 11s",
    "image_path": null
  },
  {
    "type": "code",
    "code": "# Define function to create confusion matrix\n\ndef confusion_matrix_sklearn(model, predictors, target):\n    \"\"\"\n    To plot the confusion_matrix with percentages\n\n    model: classifier\n    predictors: independent variables\n    target: dependent variable\n    \"\"\"\n    y_pred = model.predict(predictors)\n    cm = confusion_matrix(target, y_pred)\n    labels = np.asarray(\n        [\n            [\"{0:0.0f}\".format(item) + \"\\n{0:.2%}\".format(item / cm.flatten().sum())]\n            for item in cm.flatten()\n        ]\n    ).reshape(2, 2)\n\n    plt.figure(figsize=(6, 4))\n    sns.heatmap(cm, annot=labels, fmt=\"\")\n    plt.ylabel(\"True label\")\n    plt.xlabel(\"Predicted label\")",
    "output": "RandomForestClassifier(max_samples=0.5, min_samples_leaf=5, n_estimators=150,\n                       random_state=1)",
    "image_path": null
  },
  {
    "type": "markdown",
    "content": "Defining Scorer For Cross-Validation and Hyperparameter Tuning\n\u00b6"
  },
  {
    "type": "code",
    "code": "# Define F1 score as the evaluation metric for model tuning.\nscorer = metrics.make_scorer(metrics.f1_score)",
    "output": "   Unnamed: 0  Accuracy    Recall  Precision        F1\n0           0  0.772666  0.778322   0.769616  0.773944",
    "image_path": null
  },
  {
    "type": "markdown",
    "content": "I have applied my key performance metric, F1 Score."
  },
  {
    "type": "markdown",
    "content": "Model Building Using Original Data\n\u00b6"
  },
  {
    "type": "code",
    "code": "models = []  # Empty list to store all models\n\n# Appending models into list\nmodels.append((\"Bagging\", BaggingClassifier(random_state=1)))\nmodels.append((\"Random forest\", RandomForestClassifier(random_state=1)))\nmodels.append((\"GBM\", GradientBoostingClassifier(random_state=1)))\nmodels.append((\"Adaboost\", AdaBoostClassifier(random_state=1)))\nmodels.append((\"Xgboost\", XGBClassifier(random_state=1, eval_metric=\"logloss\")))\nmodels.append((\"dtree\", DecisionTreeClassifier(random_state=1)))\n\nresults1 = []  # Empty list to store all model CV scores\nnames = []     # Empty list to store name of models\n\n# Loop through all models to get mean cross-validated score\nprint(\"\\nCross-Validation Performance on Training Dataset:\\n\")\n\nfor name, model in models:\n    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)  # 5-fold CV\n    cv_result = cross_val_score(\n        estimator=model, X=X_train, y=y_train, scoring=scorer, cv=kfold\n    )\n    results1.append(cv_result)\n    names.append(name)\n    print(\"{}: {}\".format(name, cv_result.mean()))\n\nprint(\"\\nValidation Performance:\\n\")\n\nfor name, model in models:\n    model.fit(X_train, y_train)  # Fit model on training data\n    scores = f1_score(y_val, model.predict(X_val))  # Evaluate on validation set\n    print(\"{}: {}\".format(name, scores))",
    "output": "   Unnamed: 0  Accuracy    Recall  Precision        F1\n0           0  0.702864  0.712233   0.819229  0.761993",
    "image_path": null
  },
  {
    "type": "markdown",
    "content": "In this step, I trained and evaluated six classification models using the original data. Each model was assessed using 5-fold cross-validation on the training data to estimate generalization performance."
  },
  {
    "type": "code",
    "code": "# Plotting boxplots for CV scores of all models defined above\nfig = plt.figure(figsize=(10, 5))\n\nfig.suptitle(\"Algorithm Comparison\")\nax = fig.add_subplot(111)\n\nplt.boxplot(results1)\nax.set_xticklabels(names)\n\nplt.show()",
    "output": "Best parameters are {'subsample': 0.8, 'n_estimators': 150, 'max_features': 'sqrt', 'learning_rate': 0.2} with CV score=0.7954521247148147:\nCPU times: user 5.25 s, sys: 674 ms, total: 5.93 s\nWall time: 4min 56s",
    "image_path": null
  },
  {
    "type": "markdown",
    "content": "Model Benchmarking Results - Original Data\n\u00b6\nThe boosting methods far outperformed the other models (Random Forest and Decision Tree) on F1 Score.  These were the top 3 models based on performance:\nGradient Boosting (GBM):\nCV: 0.82\nValidation: 0.81\nAdaBoost:\nCV: 0.82\nValidation: 0.81\nXGBoost also performed strongly:\nCV: 0.81\nValidation: 0.80"
  },
  {
    "type": "markdown",
    "content": "Model Building Using Oversampled Data\n\u00b6"
  },
  {
    "type": "markdown",
    "content": "Oversampling will help the model learn the patterns of Denied cases (the minority class) better."
  },
  {
    "type": "code",
    "code": "print(\"Before OverSampling, counts of label '1': {}\".format(sum(y_train == 1)))\nprint(\"Before OverSampling, counts of label '0': {} \\n\".format(sum(y_train == 0)))\n\n# Synthetic Minority Over Sampling Technique\nsm = SMOTE(sampling_strategy='auto', k_neighbors=5, random_state=1)\nX_train_oversampled, y_train_oversampled = sm.fit_resample(X_train, y_train)\n\nprint(\"After OverSampling, counts of label '1': {}\".format(sum(y_train_oversampled == 1)))\nprint(\"After OverSampling, counts of label '0': {} \\n\".format(sum(y_train_oversampled == 0)))\n\nprint(\"After OverSampling, the shape of train_X: {}\".format(X_train_oversampled.shape))\nprint(\"After OverSampling, the shape of train_y: {} \\n\".format(y_train_oversampled.shape))",
    "output": "GradientBoostingClassifier(learning_rate=0.2, max_features='sqrt',\n                           n_estimators=150, random_state=1, subsample=0.8)",
    "image_path": null
  },
  {
    "type": "markdown",
    "content": "In this step, I used the SMOTE oversampling method to create synthetic data to balance the minority class (Denied).\nNow, there are 23,826 training rows total, equally split between Certified(1) and Denied (0). Each row has 18 features."
  },
  {
    "type": "code",
    "code": "models = []  # Empty list to store all the models\n\n# Appending models into list\nmodels.append((\"Bagging\", BaggingClassifier(random_state=1)))\nmodels.append((\"Random forest\", RandomForestClassifier(random_state=1)))\nmodels.append((\"GBM\", GradientBoostingClassifier(random_state=1)))\nmodels.append((\"Adaboost\", AdaBoostClassifier(random_state=1)))\nmodels.append((\"Xgboost\", XGBClassifier(random_state=1, eval_metric=\"logloss\")))\nmodels.append((\"dtree\", DecisionTreeClassifier(random_state=1)))\n\nresults1 = []  # Empty list to store all model CV scores\nnames = []     # Empty list to store name of models\n\n# Loop through all models to get mean cross-validated score\nprint(\"\\nCross-Validation Performance on Training Dataset:\\n\")\n\nfor name, model in models:\n    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)  # 5-fold CV\n    cv_result = cross_val_score(\n        estimator=model, X=X_train_oversampled, y=y_train_oversampled, scoring=scorer, cv=kfold\n    )\n    results1.append(cv_result)\n    names.append(name)\n    print(\"{}: {}\".format(name, cv_result.mean()))\n\nprint(\"\\nValidation Performance:\\n\")\n\nfor name, model in models:\n    model.fit(X_train_oversampled, y_train_oversampled)  # Fit model on oversampled training data\n    scores = f1_score(y_val, model.predict(X_val))       # Evaluate on original validation set\n    print(\"{}: {}\".format(name, scores))",
    "output": "   Unnamed: 0  Accuracy    Recall  Precision        F1\n0           0  0.803576  0.832956   0.786728  0.809182",
    "image_path": null
  },
  {
    "type": "markdown",
    "content": "In this step, I trained and evaluated six classification models using the oversampled dataset. Each model was assessed using 5-fold cross-validation on the training data to estimate generalization performance."
  },
  {
    "type": "code",
    "code": "# Plotting boxplots for CV scores of all models defined above\nfig = plt.figure(figsize=(10, 5))\n\nfig.suptitle(\"Algorithm Comparison\")\nax = fig.add_subplot(111)\n\nplt.boxplot(results1)\nax.set_xticklabels(names)\n\nplt.show()",
    "output": "   Unnamed: 0  Accuracy    Recall  Precision        F1\n0           0   0.72089  0.817153   0.776583  0.796351",
    "image_path": null
  },
  {
    "type": "markdown",
    "content": "Model Benchmarking Results - Oversampled Data\n\u00b6\nThe ensemble/boosting methods continued to perform well after balancing the class distribution with SMOTE, although there was a slight decrease in F1 scores compared to models trained on original data.\nThese were the top 3 models based on performance:\nGradient Boosting (GBM):\nCV: 0.796\nValidation: 0.797\nXGBoost:\nCV: 0.794\nValidation: 0.791\nRandom Forest:\nCV: 0.788\nValidation: 0.784"
  },
  {
    "type": "markdown",
    "content": "Model Building Using Undersampled Data\n\u00b6"
  },
  {
    "type": "code",
    "code": "rus = RandomUnderSampler(random_state=1, sampling_strategy=1)\nX_train_undersampled, y_train_undersampled = rus.fit_resample(X_train, y_train)\n\nprint(\"Before UnderSampling, counts of label '1': {}\".format(sum(y_train == 1)))\nprint(\"Before UnderSampling, counts of label '0': {} \\n\".format(sum(y_train == 0)))\n\nprint(\"After UnderSampling, counts of label '1': {}\".format(sum(y_train_undersampled == 1)))\nprint(\"After UnderSampling, counts of label '0': {} \\n\".format(sum(y_train_undersampled == 0)))\n\nprint(\"After UnderSampling, the shape of train_X: {}\".format(X_train_undersampled.shape))\nprint(\"After UnderSampling, the shape of train_y: {} \\n\".format(y_train_undersampled.shape))",
    "output": "Best parameters are {'subsample': 0.8, 'scale_pos_weight': 1, 'n_estimators': 150, 'learning_rate': 0.05, 'gamma': 0.1} with CV score=0.8017080193579454:\nCPU times: user 3.02 s, sys: 353 ms, total: 3.37 s\nWall time: 2min 2s",
    "image_path": null
  },
  {
    "type": "markdown",
    "content": "In this step, I balanced the classes by randomly reducing the number of majority class (Certified) samples to match the minority class (Denied).\nThere are now 11,846 records total with 5,923 Certified cases (1) and 5,923 Denied cases (0).\nNote -- Since a large number of Certified examples were removed, the model may miss out on valuable patterns from the majority class."
  },
  {
    "type": "code",
    "code": "models = []  # Empty list to store all models\n\n# Appending models into list\nmodels.append((\"Bagging\", BaggingClassifier(random_state=1)))\nmodels.append((\"Random forest\", RandomForestClassifier(random_state=1)))\nmodels.append((\"GBM\", GradientBoostingClassifier(random_state=1)))\nmodels.append((\"Adaboost\", AdaBoostClassifier(random_state=1)))\nmodels.append((\"Xgboost\", XGBClassifier(random_state=1, eval_metric=\"logloss\")))\nmodels.append((\"dtree\", DecisionTreeClassifier(random_state=1)))\n\nresults1 = []  # Empty list to store all model CV scores\nnames = []     # Empty list to store names of models\n\n# Loop through all models to get the mean cross-validated score\nprint(\"\\n\" \"Cross-Validation Performance on Training Dataset:\" \"\\n\")\n\nfor name, model in models:\n    kfold = StratifiedKFold(\n        n_splits=5, shuffle=True, random_state=1\n    )\n    cv_result = cross_val_score(\n        estimator=model, X=X_train_undersampled, y=y_train_undersampled, scoring=scorer, cv=kfold, n_jobs=-1\n    )\n    results1.append(cv_result)\n    names.append(name)\n    print(\"{}: {}\".format(name, cv_result.mean()))\n\nprint(\"\\n\" \"Validation Performance:\" \"\\n\")\n\nfor name, model in models:\n    model.fit(X_train_undersampled, y_train_undersampled)  # Fit model on undersampled training data\n    scores = f1_score(y_val, model.predict(X_val))         # Evaluate on validation set\n    print(\"{}: {}\".format(name, scores))",
    "output": "XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric='logloss',\n              feature_types=None, gamma=0.1, grow_policy=None,\n              importance_type=None, interaction_constraints=None,\n              learning_rate=0.05, max_bin=None, max_cat_threshold=None,\n              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n              max_leaves=None, min_child_weight=None, missing=nan,\n              monotone_constraints=None, multi_strategy=None, n_estimators=150,\n              n_jobs=None, num_parallel_tree=None, random_state=1, ...)",
    "image_path": null
  },
  {
    "type": "markdown",
    "content": "In this step, I trained and evaluated six classification models using the undersampled dataset. Each model was assessed using 5-fold cross-validation on the training data to estimate generalization performance."
  },
  {
    "type": "code",
    "code": "# Plotting boxplots for CV scores of all models defined above\nfig = plt.figure(figsize=(10, 5))\n\nfig.suptitle(\"Algorithm Comparison\")\nax = fig.add_subplot(111)\n\nplt.boxplot(results1)\nax.set_xticklabels(names)\n\nplt.show()",
    "output": "   Unnamed: 0  Accuracy    Recall  Precision        F1\n0           0  0.822295  0.855788   0.802061  0.828054",
    "image_path": null
  },
  {
    "type": "markdown",
    "content": "Model Benchmarking Results - Undersampled Data\n\u00b6\nBoosting models again outperformed simpler methods, even with a smaller training sample size. These were the top 3 models based on performance:\nGradient Boosting (GBM):\nCV: 0.71\nValidation: 0.76\nAdaBoost:\nCV: 0.697\nValidation: 0.75\nXGBoost:\nCV: 0.688\nValidation: 0.74\nOther Notes:\nGBM had the highest F1 score on both training and validation sets, indicating that it is the most stable and consistent performer across all data strategies.\nAdaBoost and XGBoost followed closely behind and showed narrow interquartile ranges (IQRs) in cross-validation, indicating low variability and reliable performance.\nRandom Forest, while decent, did not outperform the boosting models and had more spread in performance.\nBagging and Decision Tree had the lowest scores, reinforcing that simpler models are less effective in this use case."
  },
  {
    "type": "markdown",
    "content": "Hyperparameter Tuning\n\u00b6"
  },
  {
    "type": "markdown",
    "content": "Model Selection for Hyperparameter Tuning\n\u00b6\nAfter benchmarking six classifiers across original, oversampled, and undersampled datasets, I selected the following four models for tuning based on their strong F1 scores, low cross-validation variance, and consistent validation performance:\nAdaBoost (Oversampled)\nRandom Forest (Undersampled)\nGradient Boosting (Oversampled)\nXGBoost (Oversampled)\nWhy these models?:\nHigh F1 scores -- Strong balance of Precision and Recall.\nLow variance across CV folds -- Stable and reliable.\nStrong validation scores -- Good generalization, minimal overfitting.\nWhy these sampling strategies?:\nBoosting models\n(AdaBoost, GBM, XGBoost) benefit from\noversampling\nto learn from both classes equally.\nRandom Forest\nperforms well even with\nundersampling\n, enabling faster training while still capturing key patterns."
  },
  {
    "type": "markdown",
    "content": "Tuning AdaBoost Using Oversampled Data\n\u00b6"
  },
  {
    "type": "code",
    "code": "%%time\n\n# Defining the model\nModel = AdaBoostClassifier(random_state=1)\n\n# Parameter grid to pass in RandomizedSearchCV\nparam_grid = {\n    \"n_estimators\": [50, 100, 150, 200],\n    \"learning_rate\": [0.01, 0.05, 0.1, 0.2, 0.5],\n    \"estimator\": [\n        DecisionTreeClassifier(max_depth=1, random_state=1),\n        DecisionTreeClassifier(max_depth=2, random_state=1),\n        DecisionTreeClassifier(max_depth=3, random_state=1)\n    ]\n}\n\n# Calling RandomizedSearchCV\nrandomized_cv = RandomizedSearchCV(\n    estimator=Model,\n    param_distributions=param_grid,\n    n_iter=50,\n    n_jobs=-1,\n    scoring=scorer,          # Using f1_score as defined earlier\n    cv=5,                    # 5-fold cross-validation\n    random_state=1\n)\n\n# Fitting parameters in RandomizedSearchCV on oversampled training data\nrandomized_cv.fit(X_train_oversampled, y_train_oversampled)\n\nprint(\"Best parameters are {} with CV score={}\".format(\n    randomized_cv.best_params_, randomized_cv.best_score_\n))",
    "output": "   Unnamed: 0  Accuracy    Recall  Precision        F1\n0           0  0.724524  0.823248    0.77739  0.799662",
    "image_path": null
  },
  {
    "type": "markdown",
    "content": "Best hyperparameters found:\nn_estimators: 200\nlearning_rate: 0.1\nestimator: DecisionTreeClassifier with max_depth=3"
  },
  {
    "type": "code",
    "code": "# Setting the best parameters manually\ntuned_ada = AdaBoostClassifier(\n    n_estimators=200,\n    learning_rate=0.1,\n    estimator=DecisionTreeClassifier(max_depth=3, random_state=1)\n)\n# Fitting the tuned model on the oversampled training data\ntuned_ada.fit(X_train_oversampled, y_train_oversampled)",
    "output": "  Unnamed: 0  Gradient Boosting (Oversampled Data)  XGBoost (Oversampled Data)  AdaBoost (Oversampled Data)  Random Forest (Undersampled Data)\n0   Accuracy                              0.803576                    0.822295                     0.801729                           0.772666\n1     Recall                              0.832956                    0.855788                     0.818182                           0.778322\n2  Precision                              0.786728                    0.802061                     0.792117                           0.769616\n3         F1                              0.809182                    0.828054                     0.804938                           0.773944",
    "image_path": null
  },
  {
    "type": "code",
    "code": "# Evaluate performance on the training (oversampled) data\nada_train_perf = model_performance_classification_sklearn(tuned_ada, X_train_oversampled, y_train_oversampled)\nada_train_perf\n\nprint(\"\\nAdaBoost - Performance on Oversampled Training Data:\\n\")\ndisplay(ada_train_perf)",
    "output": "  Unnamed: 0  Gradient Boosting (Oversampled Data)  XGBoost (Oversampled Data)  AdaBoost (Oversampled Data)  Random Forest (Undersampled Data)\n0   Accuracy                              0.720890                    0.724524                     0.719872                           0.702864\n1     Recall                              0.817153                    0.823248                     0.807575                           0.712233\n2  Precision                              0.776583                    0.777390                     0.780560                           0.819229\n3         F1                              0.796351                    0.799662                     0.793838                           0.761993",
    "image_path": null
  },
  {
    "type": "code",
    "code": "# Evaluate performance on the validation (unseen) data\nada_val_perf = model_performance_classification_sklearn(tuned_ada, X_val, y_val)\nada_val_perf\n\nprint(\"\\nAdaBoost - Performance on Validation Data:\\n\")\ndisplay(ada_val_perf)",
    "output": "  Unnamed: 0  GBM Delta  XGBoost Delta\n0   Accuracy  -0.082686      -0.097771\n1     Recall  -0.015803      -0.032540\n2  Precision  -0.010145      -0.024672\n3         F1  -0.012831      -0.028392",
    "image_path": null
  },
  {
    "type": "markdown",
    "content": "Observations on Tuning - AdaBoost (Oversampled)\n\u00b6\nOn the training data, the model achieved strong performance across all metrics, including F1 score (0.8), precision (0.80), and recall (0.81). This suggests it learned the balanced data well without overfitting.\nOn the validation set, the model maintained comparable performance, with only a slight drop in metrics. This indicates the model generalizes well to unseen data.\nThe F1 score remained high across both sets, confirming that the model balances precision and recall effectively, an important requirement for this classification task.\nRecall remained strong, which is valuable in the context of visa approval, where correctly identifying denied cases is critical to ensure fairness and prevent approval errors."
  },
  {
    "type": "markdown",
    "content": "Tuning Random Forest Using Undersampled Data\n\u00b6"
  },
  {
    "type": "code",
    "code": "%%time\n\n# Defining model\nModel = RandomForestClassifier(random_state=1)\n\n# Parameter grid to pass into RandomizedSearchCV\nparam_grid = {\n    \"n_estimators\": [50, 100, 150, 200],  # Number of trees in the forest\n    \"min_samples_leaf\": np.arange(1, 6),  # Min samples required at a leaf node\n    \"max_features\": [np.arange(3, 18, 3), 'sqrt'],  # Max features to consider at each split\n    \"max_samples\": np.arange(0.5, 1.0, 0.1)  # Fraction of samples used to train each tree\n}\n\n# Calling RandomizedSearchCV\nrandomized_cv = RandomizedSearchCV(\n    estimator=Model,\n    param_distributions=param_grid,\n    n_iter=50,\n    n_jobs=-1,\n    scoring=scorer,\n    cv=5,  # 5-fold cross-validation\n    random_state=1\n)\n\n# Fitting parameters in RandomizedSearchCV on undersampled data\nrandomized_cv.fit(X_train_undersampled, y_train_undersampled)\n\nprint(\"Best parameters are {} with CV score={}:\".format(\n    randomized_cv.best_params_,\n    randomized_cv.best_score_\n))",
    "output": "   Unnamed: 0  Accuracy    Recall  Precision        F1\n0           0  0.755556  0.861057   0.791367  0.824742",
    "image_path": null
  },
  {
    "type": "markdown",
    "content": "Best hyperparameters found:\nn_estimators = 150\nmin_samples_leaf = 5\nmax_features = 'sqrt'\nmax_samples = 0.5"
  },
  {
    "type": "code",
    "code": "# Defining the best model using tuned hyperparameters\ntuned_rf2 = RandomForestClassifier(\n    max_features='sqrt',\n    random_state=1,\n    max_samples=0.5,\n    n_estimators=150,\n    min_samples_leaf=5\n)\n\n# Fitting the model on undersampled training data\ntuned_rf2.fit(X_train_undersampled, y_train_undersampled)",
    "output": "   Unnamed: 0  Accuracy    Recall  Precision        F1\n0           0  0.756863  0.857143   0.794918  0.824859",
    "image_path": null
  },
  {
    "type": "code",
    "code": "# Evaluate model performance on the train data\nrf2_train_perf = model_performance_classification_sklearn(\n    tuned_rf2, X_train_undersampled, y_train_undersampled\n)\nrf2_train_perf\n\nprint(\"\\nRandom Forest - Performance on Undersampled Training Data:\\n\")\ndisplay(rf2_train_perf)",
    "output": "",
    "image_path": "extracted_images_beta\\image_15.png"
  },
  {
    "type": "code",
    "code": "# Evaluate model performance on the validation data\nrf2_val_perf = model_performance_classification_sklearn(tuned_rf2, X_val, y_val)\nrf2_val_perf\n\nprint(\"\\nRandom Forest - Performance on Validation Data:\\n\")\ndisplay(rf2_val_perf)",
    "output": "",
    "image_path": null
  },
  {
    "type": "markdown",
    "content": "Observations on Tuning - Random Forest (Undersampled)\n\u00b6\nF1 Score on validation set was 0.76, slightly lower than boosting models.\nTraining F1 Score was 0.77, showing minimal overfitting and good stability.\nValidation Precision was strong (0.82), indicating the model effectively avoids false positives.\nValidation Recall was lower (0.71), which is a drawback for this use case where minimizing false negatives is important.\nOverall, performance was solid but did not exceed the tuned boosting models."
  },
  {
    "type": "markdown",
    "content": "Tuning Using Gradient Boosting With Oversampled Data\n\u00b6"
  },
  {
    "type": "code",
    "code": "%%time\n\n# Defining model\nModel = GradientBoostingClassifier(random_state=1)\n\n# Defining the hyperparameters to tune\nparam_grid = {\n    \"n_estimators\": np.arange(50, 201, 50),        # Number of boosting stages\n    \"learning_rate\": [0.01, 0.05, 0.1, 0.2],       # Step size shrinkage\n    \"subsample\": [0.8, 1.0],                       # % of samples used for fitting each base learner\n    \"max_features\": ['sqrt', 'log2']               # Max features for best split\n}\n\n# RandomizedSearchCV setup\nrandomized_cv = RandomizedSearchCV(\n    estimator=Model,\n    param_distributions=param_grid,\n    scoring=scorer,            # Using F1 score\n    n_iter=50,                 # Number of random combinations to try\n    n_jobs=-1,\n    cv=5,                      # 5-fold cross-validation\n    random_state=1\n)\n\n# Fitting the model on oversampled training data\nrandomized_cv.fit(X_train_oversampled, y_train_oversampled)\n\nprint(\"Best parameters are {} with CV score={}:\".format(\n    randomized_cv.best_params_,\n    randomized_cv.best_score_\n))",
    "output": "",
    "image_path": null
  },
  {
    "type": "markdown",
    "content": "Best parameters found:\nn_estimators = 150\nlearning_rate = 0.2\nsubsample = 0.8\nmax_features = 'sqrt'"
  },
  {
    "type": "code",
    "code": "# Define the best model using the tuned hyperparameters\ntuned_gbm = GradientBoostingClassifier(\n    max_features='sqrt',\n    random_state=1,\n    learning_rate=0.2,\n    n_estimators=150,\n    subsample=0.8\n)\n\n# Fit the model on the oversampled training data\ntuned_gbm.fit(X_train_oversampled, y_train_oversampled)",
    "output": "",
    "image_path": null
  },
  {
    "type": "code",
    "code": "# Evaluate model performance on the train data\ngbm_train_perf = model_performance_classification_sklearn(\n    tuned_gbm, X_train_oversampled, y_train_oversampled\n)\ngbm_train_perf\n\nprint(\"\\nGradient Boosting - Performance on Oversampled Training Data:\\n\")\ndisplay(gbm_train_perf)",
    "output": "",
    "image_path": null
  },
  {
    "type": "code",
    "code": "# Evaluate model performance on the validation data\ngbm_val_perf = model_performance_classification_sklearn(tuned_gbm, X_val, y_val)\ngbm_val_perf\n\nprint(\"\\nGradient Boosting - Performance on Validation Data:\\n\")\ndisplay(gbm_val_perf)",
    "output": "",
    "image_path": null
  },
  {
    "type": "markdown",
    "content": "Observations on Tuning - Gradient Boosting (Oversampled)\n\u00b6\nThe model achieved strong performance on the training set, with high Accuracy, Precision, Recall, and F1 Score, indicating that it effectively learned the balanced patterns in the oversampled data.\nThe model achieved a cross-validated F1 score (0.796), indicating strong performance during training with oversampled data."
  },
  {
    "type": "markdown",
    "content": "Tuning XGBoost Using Oversampled Data\n\u00b6"
  },
  {
    "type": "code",
    "code": "%%time\n\n# Defining model\nModel = XGBClassifier(random_state=1, eval_metric='logloss')\n\n# Defining the hyperparameters to tune\nparam_grid = {\n    'n_estimators': [50, 100, 150, 200],       # Number of boosting rounds\n    'scale_pos_weight': [1],                   # 1 is fine here since data is already oversampled and balanced\n    'learning_rate': [0.01, 0.05, 0.1, 0.2],   # Step size shrinkage\n    'gamma': [0, 0.1, 0.3, 0.5],               # Minimum loss reduction to make a split\n    'subsample': [0.7, 0.8, 1.0]               # Fraction of training samples for growing each tree\n}\n\n# RandomizedSearchCV setup\nrandomized_cv = RandomizedSearchCV(\n    estimator=Model,\n    param_distributions=param_grid,\n    n_iter=50,\n    n_jobs=-1,\n    scoring=scorer,     # Using F1 score\n    cv=5,               # 5-fold cross-validation\n    random_state=1\n)\n\n# Fit the model on oversampled data\nrandomized_cv.fit(X_train_oversampled, y_train_oversampled)\n\nprint(\"Best parameters are {} with CV score={}:\".format(\n    randomized_cv.best_params_,\n    randomized_cv.best_score_\n))",
    "output": "",
    "image_path": null
  },
  {
    "type": "markdown",
    "content": "Best parameters found:\nn_estimators: 150\nlearning_rate: 0.05\ngamma: 0.1\nsubsample: 0.8\nscale_pos_weight: 1\nCV F1 score: 0.802"
  },
  {
    "type": "code",
    "code": "## Defining the best model using tuned hyperparameters\nxgb2 = XGBClassifier(\n    random_state=1,\n    eval_metric='logloss',\n    subsample=0.8,\n    scale_pos_weight=1,\n    n_estimators=150,\n    learning_rate=0.05,\n    gamma=0.1\n)\n\n# Fit the model on the oversampled training data\nxgb2.fit(X_train_oversampled, y_train_oversampled)",
    "output": "",
    "image_path": null
  },
  {
    "type": "code",
    "code": "# Evaluate model performance on the train data\nxgb2_train_perf = model_performance_classification_sklearn(\n    xgb2, X_train_oversampled, y_train_oversampled\n)\nxgb2_train_perf\n\nprint(\"\\nXGBoost - Performance on Oversampled Training Data:\\n\")\ndisplay(xgb2_train_perf)",
    "output": "",
    "image_path": null
  },
  {
    "type": "code",
    "code": "# Evaluate model performance on the validation data\nxgb2_val_perf = model_performance_classification_sklearn(xgb2, X_val, y_val)\nxgb2_val_perf\n\nprint(\"\\nXGBoost - Performance on Validation Data:\\n\")\ndisplay(xgb2_val_perf)",
    "output": "",
    "image_path": null
  },
  {
    "type": "markdown",
    "content": "Observations on Tuning - XGBoost (Oversampled)\n\u00b6\nXGBoost handled the oversampled dataset well and is a robust, high-performing candidate for final model selection.\nOn the oversampled training set, we see high Precision, Recall (0.86 - Highest we've seen), and F1 Score (0.83).\nOn the validation set, performance remained consistent, indicating good generalization and no overfitting."
  },
  {
    "type": "markdown",
    "content": "Model Performance Comparison & Final Selection\n\u00b6"
  },
  {
    "type": "markdown",
    "content": "In the next step, I will compile performance metrics for each of the four tuned models, for both the training and validation sets, and evaluate them based on F1 Score, Recall, Prioritization, and Accuracy.\nUsing this analysis, I will choose a final model to implement."
  },
  {
    "type": "code",
    "code": "# Training performance comparison\n\nmodels_train_comp_df = pd.concat(\n    [\n        gbm_train_perf.T,\n        xgb2_train_perf.T,\n        ada_train_perf.T,\n        rf2_train_perf.T,\n    ],\n    axis=1,\n)\nmodels_train_comp_df.columns = [\n    \"Gradient Boosting (Oversampled Data)\",\n    \"XGBoost (Oversampled Data)\",\n    \"AdaBoost (Oversampled Data)\",\n    \"Random Forest (Undersampled Data)\",\n]\nprint(\"\\nTraining Performance Comparison:\\n\")\nmodels_train_comp_df",
    "output": "",
    "image_path": null
  },
  {
    "type": "markdown",
    "content": "Observations on Tuning Comparison - Training Performance:\n\u00b6\nXGBoost (oversampled) outperforms in all performance metrics on the train data and proves to be the most balanced model option - F1 Score (0.83), Recall (0.86), Precision (0.8), and Accuracy (0.82)\nGBM (oversampled) is a close runner-up in performance across all train data metrics.\nAdaBoost (oversampled) lags slightly behind.\nRandom Forest (undersampled) is clearly not performing as well as the boosting models."
  },
  {
    "type": "code",
    "code": "# Validation performance comparison\n\nmodels_val_comp_df = pd.concat(\n    [\n        gbm_val_perf.T,\n        xgb2_val_perf.T,\n        ada_val_perf.T,\n        rf2_val_perf.T,\n    ],\n    axis=1,\n)\nmodels_val_comp_df.columns = [\n    \"Gradient Boosting (Oversampled Data)\",\n    \"XGBoost (Oversampled Data)\",\n    \"AdaBoost (Oversampled Data)\",\n    \"Random Forest (Undersampled Data)\",\n]\nprint(\"\\nValidation Performance Comparison:\\n\")\nmodels_val_comp_df",
    "output": "",
    "image_path": null
  },
  {
    "type": "markdown",
    "content": "Observations on Tuning Comparison - Validation Performance:\n\u00b6\nIn terms of F1 Score, GBM (oversampled) has the closest match between train (0.81) and test data performance (0.8).\nHowever, XGBoost (oversampled) has the slight edge on performance metrics across all categories -- F1 (0.8), Recall (0.82), Precision (0.78), and Accuracy (0.72) with minimal difference between train and validation data sets."
  },
  {
    "type": "markdown",
    "content": "Evaluating Train & Validation Deltas\n\u00b6\nI want to compare the differences between training and validation metrics for GBM (oversampled) and XGBoost (oversampled), as the ideal model should perform similarly on both data sets."
  },
  {
    "type": "code",
    "code": "# Calculate deltas (Validation - Training) for each metric\ngbm_delta = gbm_val_perf.T - gbm_train_perf.T\nxgb_delta = xgb2_val_perf.T - xgb2_train_perf.T\n\n# Combine into one DataFrame\ndelta_compare = pd.concat([gbm_delta, xgb_delta], axis=1)\ndelta_compare.columns = ['GBM Delta', 'XGBoost Delta']\n\n# Display the delta table\nprint(\"\\nDelta in Performance (Validation - Training):\\n\")\ndisplay(delta_compare)",
    "output": "",
    "image_path": null
  },
  {
    "type": "markdown",
    "content": "Selection of Best Model & Reasoning:\n\u00b6\nWhile both\nGBM (oversampled)\nand\nXGBoost (oversampled)\ndemonstrated strong performance, I'm choosing XGBoost (oversampled) as the final model based on the following observations:\nHighest Overall Performance:\nXGBoost (oversampled) achieved the best F1 Score on both the training set (0.83) and the validation set (0.80), outperforming all other models.\nConsistent Precision and Recall:\nXGBoost (oversampled) maintained strong Precision (0.80 train and 0.80 validation) and Recall (0.85 train and 0.82 validation), which is especially important in this context.\nHigher Recall\nmeans fewer false negatives (e.g., fewer qualified applicants denied), making visa approval more fair and equitable.\nStrong Precision\nsupports a low false positive rate, helping ensure unqualified applicants aren't mistakenly approved.\nAcceptable Generalization Gap:\nWhile GBM (oversampled) showed a slightly smaller F1 delta (\u22120.013) compared to XGBoost (oversampled) (\u22120.028), XGBoost still demonstrates good generalization, with all metric deltas between training and validation falling within reasonable limits.\nRobustness and Scalability:\nXGBoost (oversampled) handles large, imbalanced, or complex datasets extremely well. Its regularization capabilities make it more flexible and better at avoiding overfitting than traditional GBM.\nConclusion:\nXGBoost (oversampled) offers the best combination of high performance and generalization ability. It is the most consistent and robust model and will be used for final evaluation on the test set."
  },
  {
    "type": "markdown",
    "content": "Check Model Against Test Data\n\u00b6"
  },
  {
    "type": "markdown",
    "content": "To validate my selection of XGBoost (oversampled), I'm checking its performance against the test data set.\nI'm also checking its closest competitor, GBM (oversampled)."
  },
  {
    "type": "code",
    "code": "# Evaluate the final model (XGBoost with oversampled data) on the test set\ntest_xgboost = model_performance_classification_sklearn(xgb2, X_test, y_test)\ntest_xgboost\n\nprint(\"\\nXGBoost (Oversampled) - Performance on Test Data:\\n\")\ndisplay(test_xgboost)",
    "output": "",
    "image_path": null
  },
  {
    "type": "code",
    "code": "# Evaluate the GBM (oversampled) model on the test set\ntest_gbm = model_performance_classification_sklearn(tuned_gbm, X_test, y_test)\ntest_gbm\n\nprint(\"\\nGradient Boosting (Oversampled) - Performance on Test Data:\\n\")\ndisplay(test_gbm)",
    "output": "",
    "image_path": null
  },
  {
    "type": "markdown",
    "content": "Confirmed - XGBoost (Oversampled) is Best Model For Predicting Visa Approval:\n\u00b6\nHigher Recall (0.86) means XGBoost is catching slightly more true positives.\nIn a visa approval use case, that means fewer qualified applicants are wrongly denied.\nPrecision is nearly tied between the two models, so XGBoost is not compromising on false positives.\nF1 scores are almost identical, showing both models balance Precision and Recall well -- but XGBoost is better on Recall, which matters most in this context.\nXGBoost (Oversampled) is the final model choice."
  },
  {
    "type": "markdown",
    "content": "Evaluate Feature Importance\n\u00b6"
  },
  {
    "type": "code",
    "code": "feature_names = X_train.columns\nimportances = xgb2.feature_importances_  # Extract feature importances from the XGBoost model\nindices = np.argsort(importances)\n\nplt.figure(figsize=(5, 5))\nplt.title(\"Feature Importances\")\nplt.barh(range(len(indices)), importances[indices], color=\"violet\", align=\"center\")\nplt.yticks(range(len(indices)), [feature_names[i] for i in indices])\nplt.xlabel(\"Relative Importance\")\nplt.show()",
    "output": "",
    "image_path": null
  },
  {
    "type": "markdown",
    "content": "Feature Importance Interpretation\n\u00b6\nTop Predictors of Visa Certification:\nDoctorate & Master's Degrees\n-- Applicants with advanced degrees had the highest likelihood of certification, confirming earlier EDA insights that higher education levels correlate strongly with approval.\nHas Job Experience\n-- Prior work experience was a key driver of approval, consistent with EDA trends showing significantly higher certification rates among experienced applicants.\nRegion of Employment (West, Midwest)\n-- Geographic regions like the West and Midwest contributed more to approval decisions, aligning with slight regional wage advantages and demand concentrations noted in EDA.\nContinent (Europe)\n-- Applicants from Europe saw higher approval rates compared to other continents\u2014particularly Asia, North America, and South America\u2014reinforcing observed geographic patterns.\nLess Influential Features:\nRequires Job Training\n-- This feature had limited impact, likely due to the small number of applicants requiring training. It may also carry less predictive weight compared to stronger qualifiers like education or experience.\nNormalized Wage (Originally Unit of Wage), Year of Establishment, Number of Employees\nThese numeric employer-related features showed minimal predictive influence, reflecting low correlations observed during EDA.\nThe normalized wage didn\u2019t sharply distinguish certified from denied cases.\nYear of establishment and company size may signal organizational stability but appeared less decisive than applicant qualifications.\nOverall, visa approval outcomes were shaped more by applicant-level factors than employer scale."
  },
  {
    "type": "markdown",
    "content": "Executive Summary & Recommendations\n\u00b6"
  },
  {
    "type": "markdown",
    "content": "As the number of visa applications continues to rise annually, the need for scalable, efficient, and equitable processing has become critical. The EasyVisa project applied machine learning to streamline the U.S. Office of Foreign Labor Certification\u2019s (OFLC) visa adjudication process. After testing multiple classifiers and resampling strategies,\nXGBoost trained on oversampled data\nemerged as the best-performing model, offering a strong balance of Precision and Recall, especially in identifying qualified applicants.\nKey Takeaways:\n\u00b6\nTop Predictors of Approval\n: Education level (Master\u2019s or Doctorate) and prior job experience were the strongest signals of visa certification.\nGeographic and Regional Disparities\n: Applicants from Europe had the highest approval rates; North and South America had the lowest.\nModel Performance\n: XGBoost (oversampled) achieved the best F1 Score (0.83 train, 0.80 validation, 0.80 test) and the highest Recall (0.86), making it well-suited for minimizing false denials.\nBoosting Outperformed Bagging\n: Boosting methods (XGBoost, AdaBoost, GBM) consistently outperformed Random Forest, Bagging, and Decision Trees across all data strategies.\nWhy XGBoost (Oversampled) Was Chosen as the Final Model:\n\u00b6\nAmong the four tuned models tested,\nXGBoost, Gradient Boosting, AdaBoost, and Random Forest\n, XGBoost trained on oversampled data was selected based on its superior and consistent performance:\nTop F1 Score Across All Sets:\nTrain:\n0.83\u2003|\nValidation:\n0.80\u2003|\nTest:\n0.82\nF1 Score balances Precision and Recall, making it ideal for minimizing both false approvals and false denials.\nHighest Recall on Test Data (0.86):\nCritical for reducing false negatives \u2014 ensuring qualified applicants are not wrongly denied.\nStrong Precision on Test Data (0.79):\nMaintains quality of approvals by minimizing unqualified certifications.\nMore Consistent Than Other Models:\nSlightly outperformed Gradient Boosting, especially in Recall and test set performance.\nAdaBoost and Random Forest showed weaker generalization and lower F1 scores.\nScalable and Interpretable:\nXGBoost is optimized for large, imbalanced datasets and provides clear feature importance for auditability and stakeholder trust.\nRecommendations\n\u00b6\nModel Deployment & Workflow Integration\n\u00b6\nAdopt the Final XGBoost Model\nDeploy it within OFLC\u2019s pipeline to automatically flag high-likelihood approvals and surface edge cases for human review.\nUse the Model to Prioritize Reviews\nFast-track low-risk applications and route complex or borderline cases for additional review to improve throughput.\nLeverage Risk Scores for Smarter Triage\nUse XGBoost\u2019s probability scores (not just binary outcomes) to create a risk-ranking system for more efficient queue management.\nFairness, Auditability & Continuous Improvement\n\u00b6\nPromote Fairness via High Recall\nMaintain high recall to reduce false denials and uphold equity in the review process.\nCompare Model vs. Human Outcomes\nRegularly audit prediction mismatches to identify inconsistencies and potential training or policy gaps.\nIncorporate Reviewer Feedback Loops\nEnable human reviewers to flag cases for retraining or model refinement over time.\nMonitor Model Health\nTrack performance metrics, retrain with fresh data, and monitor for drift or demographic bias.\nPolicy Alignment & Process Optimization\n\u00b6\nPrioritize Education & Experience\nEmphasize these features in review criteria, as they were the most predictive indicators of approval.\nDe-emphasize Employer Characteristics\nReduce reliance on features like company size, founding year, or wage unit, which had little predictive power.\nSupport Underserved Regions\nConsider outreach or educational resources for regions with lower approval rates (e.g., South and North America).\nData Infrastructure & Enrichment\n\u00b6\nStandardize and Automate Data Pipelines\nEnsure clean and consistent inputs with automated normalization and encoding workflows.\nImprove Employer Data Quality\nEncourage more consistent reporting of fields like\nrequires_job_training\nand\nunit_of_wage\n.\nEnrich Dataset for Deeper Insights\nConsider adding features like job codes, industry type, company status, or denial reasons to uncover deeper patterns and improve future models."
  }
]