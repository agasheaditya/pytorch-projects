{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd434156",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from ollama import chat \n",
    "from ollama import ChatResponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53c27092",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_json_path = '../parsed_output-beta.json' \n",
    "rubrics_json_path = '../data/rubrics.json' \n",
    "\n",
    "with open(submission_json_path, 'r') as file:\n",
    "    submission_dict = json.load(file)\n",
    "\n",
    "with open(rubrics_json_path, 'r') as file:\n",
    "    rubrics_dict = json.load(file)\n",
    "\n",
    "\n",
    "problem_statement = \"\"\"\n",
    "\n",
    "# Problem Statement\n",
    "\n",
    "## Business Context\n",
    "Business communities in the United States are facing high demand for human resources, but one of the constant challenges is identifying and attracting the right talent, which is perhaps the most important element in remaining competitive. Companies in the United States look for hard-working, talented, and qualified individuals both locally as well as abroad.\n",
    "\n",
    "The Immigration and Nationality Act (INA) of the US permits foreign workers to come to the United States to work on either a temporary or permanent basis. The act also protects US workers against adverse impacts on their wages or working conditions by ensuring US employers' compliance with statutory requirements when they hire foreign workers to fill workforce shortages. The immigration programs are administered by the Office of Foreign Labor Certification (OFLC).\n",
    "\n",
    "OFLC processes job certification applications for employers seeking to bring foreign workers into the United States and grants certifications in those cases where employers can demonstrate that there are not sufficient US workers available to perform the work at wages that meet or exceed the wage paid for the occupation in the area of intended employment.\n",
    "\n",
    "## Objective\n",
    "In FY 2016, the OFLC processed 775,979 employer applications for 1,699,957 positions for temporary and permanent labor certifications. This was a nine percent increase in the overall number of processed applications from the previous year. The process of reviewing every case is becoming a tedious task as the number of applicants is increasing every year.\n",
    "\n",
    "The increasing number of applicants every year calls for a Machine Learning based solution that can help in shortlisting the candidates having higher chances of VISA approval. OFLC has hired the firm EasyVisa for data-driven solutions. You as a data scientist at EasyVisa have to analyze the data provided and, with the help of a classification model:\n",
    "\n",
    "* Facilitate the process of visa approvals.\n",
    "* Recommend a suitable profile for the applicants for whom the visa should be certified or denied based on the drivers that significantly influence the case status.\n",
    "\n",
    "---\n",
    "\n",
    "## Data Description\n",
    "_The data contains the different attributes of employee and the employer. The detailed data dictionary is given below._\n",
    "\n",
    "__case_id__: ID of each visa application \\\n",
    "__continent__: Information of continent the employee \\\n",
    "__education_of_employee__: Information of education of the employee \\\n",
    "__has_job_experience__: Does the employee has any job experience? Y= Yes; N = No \\\n",
    "__requires_job_training__: Does the employee require any job training? Y = Yes; N = No \\\n",
    "__no_of_employees__: Number of employees in the employer's company \\\n",
    "__yr_of_estab__: Year in which the employer's company was established \\\n",
    "__region_of_employment__: Information of foreign worker's intended region of employment in the US. \\\n",
    "__prevailing_wage__: Average wage paid to similarly employed workers in a specific occupation in the area of intended employment. The purpose of the prevailing wage is to ensure that the foreign worker is not underpaid compared to other workers offering the same or similar service in the same area of employment. \\\n",
    "__unit_of_wage__: Unit of prevailing wage. Values include Hourly, Weekly, Monthly, and Yearly. \\\n",
    "__full_time_position__: Is the position of work full-time? Y = Full Time Position; N = Part Time Position \\\n",
    "__case_status__: Flag indicating if the Visa was certified or denied\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eca930d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "You are a data science expert and you need to evaluate the assignment submission provided by a student and give POINTS or MARKS for each task performed and also give final scores for the provided submission out of 60. \n",
    "You should check the submission thoroughly and give very brief feedback overall and most importantly 'scores/marks/points' for each section by strictly following the rubrics and finally provide the total marks out of 60.\n",
    "\n",
    "Here is the problem statement: {problem_statement}. \n",
    "Here is the rubric: {rubrics_dict}. \n",
    "Here is the submission from student: {submission_dict}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5cde8226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, let's see what the user is asking here. They provided a list of code snippets and outputs from various machine learning models, probably from a Jupyter notebook. The user might be looking for an analysis of these models' performance, hyperparameter tuning results, or perhaps an explanation of the code they've written.\n",
      "\n",
      "First, I need to parse through each code block and the corresponding outputs. Let me go step by step.\n",
      "\n",
      "The first code block mentions a Gradient Boosting Classifier with parameters like n_estimators=50, learning_rate=1.0, etc. The output here is the model's parameters, which might be part of hyperparameter tuning. Then there's a section where they check recall, precision, and accuracy on the test set for different models: dt2_tuned (Decision Tree), ada2_tuned (AdaBoost), and gboost2_tuned (Gradient Boosting). The outputs for these models would be the metrics on the test set.\n",
      "\n",
      "Looking at the outputs, the user might have run these models and want to compare their performance. They might also be interested in understanding which model performed best based on the metrics. For example, the Decision Tree model's test accuracy is 0.77, AdaBoost is 0.81, and Gradient Boosting is 0.82. The user might be looking for insights into why one model outperforms others or how to further optimize them.\n",
      "\n",
      "Additionally, there's a feature importance plot for AdaBoost, which could help in understanding which features are most influential. The user might want to know how to interpret these feature importances or how they can use this information for further model improvements.\n",
      "\n",
      "Another thing to note is the use of hyperparameter tuning with RandomizedSearchCV. The user might be interested in how the tuning process worked, which parameters were found to be optimal, and how those parameters affected the model's performance.\n",
      "\n",
      "Potential issues could include overfitting, especially if the training metrics are much higher than the test metrics. For example, if the training accuracy is significantly higher than the test accuracy, that might indicate overfitting. However, the provided outputs don't include training metrics, so I can't assess that without more data.\n",
      "\n",
      "The user might also be looking for recommendations on which model to deploy based on the test metrics. Since Gradient Boosting has the highest accuracy and precision, it might be the preferred model. However, they should also consider other factors like computational resources, interpretability, and business requirements.\n",
      "\n",
      "I should also check if the user has any specific questions about the code, the results, or the models. Since they didn't ask a direct question, maybe they want a summary of the findings or an explanation of the models' performance. Alternatively, they might need help with next steps, like further tuning or deploying the model.\n",
      "\n",
      "In summary, the user's request is to analyze the provided code and outputs to understand the model performance, hyperparameter tuning results, and possibly recommendations for model selection or improvement. I'll need to present a clear analysis of each model's metrics, discuss the hyperparameter tuning process, and offer insights into the feature importances and potential next steps.\n",
      "</think>\n",
      "\n",
      "### **Analysis of Model Performance and Hyperparameter Tuning**\n",
      "\n",
      "Here's a breakdown of the models, their hyperparameters, and performance metrics based on the provided code and outputs:\n",
      "\n",
      "---\n",
      "\n",
      "### **1. Decision Tree (dt2_tuned)**\n",
      "- **Hyperparameters**:  \n",
      "  - `max_depth=3` (from earlier tuning)  \n",
      "  - Other parameters were not explicitly shown, but the final model was tuned using `RandomizedSearchCV`.  \n",
      "- **Test Metrics**:  \n",
      "  - **Recall**: ~0.77  \n",
      "  - **Precision**: ~0.78  \n",
      "  - **Accuracy**: ~0.77  \n",
      "- **Observation**:  \n",
      "  - The model performs reasonably but isn't the top performer. It may benefit from further tuning (e.g., adjusting `max_depth` or using ensemble methods).\n",
      "\n",
      "---\n",
      "\n",
      "### **2. AdaBoost (ada2_tuned)**\n",
      "- **Hyperparameters**:  \n",
      "  - `n_estimators=300`, `learning_rate=1.0`, `estimator=DecisionTreeClassifier(max_depth=3)`, `algorithm='SAMME'`  \n",
      "- **Test Metrics**:  \n",
      "  - **Recall**: ~0.81  \n",
      "  - **Precision**: ~0.83  \n",
      "  - **Accuracy**: ~0.81  \n",
      "- **Observation**:  \n",
      "  - AdaBoost achieves strong performance, especially with high precision. The choice of `SAMME` algorithm and deeper trees (`max_depth=3`) likely contributed to better generalization.  \n",
      "  - Feature importances (from the plot) could help identify key predictors.\n",
      "\n",
      "---\n",
      "\n",
      "### **3. Gradient Boosting (gboost2_tuned)**\n",
      "- **Hyperparameters**:  \n",
      "  - `n_estimators=50`, `learning_rate=1.0`, `max_depth=5`, `min_samples_split=20`, `min_samples_leaf=2`, `max_features=0.1`, `loss='log_loss'`  \n",
      "- **Test Metrics**:  \n",
      "  - **Recall**: ~0.82  \n",
      "  - **Precision**: ~0.84  \n",
      "  - **Accuracy**: ~0.82  \n",
      "- **Observation**:  \n",
      "  - The Gradient Boosting model outperforms the others, achieving the highest accuracy and precision. The combination of `max_depth=5` and `learning_rate=1.0` suggests a balance between model complexity and convergence.  \n",
      "  - The `max_features=0.1` parameter indicates a focus on reducing overfitting by limiting feature usage per tree.\n",
      "\n",
      "---\n",
      "\n",
      "### **Key Insights**\n",
      "1. **Model Comparison**:  \n",
      "   - **Gradient Boosting** is the top performer, followed by **AdaBoost**, then **Decision Trees**.  \n",
      "   - Gradient Boosting's high precision and recall suggest it's best suited for this dataset, especially if the goal is to minimize false negatives (e.g., in fraud detection or medical diagnosis).\n",
      "\n",
      "2. **Hyperparameter Tuning**:  \n",
      "   - All models were tuned using `RandomizedSearchCV`, which efficiently explores the parameter space.  \n",
      "   - Gradient Boosting's optimal parameters (e.g., `max_depth=5`, `learning_rate=1.0`) likely reflect a trade-off between model complexity and training speed.\n",
      "\n",
      "3. **Feature Importance**:  \n",
      "   - The AdaBoost model's feature importance plot (not shown here) would highlight the most impactful predictors. This could guide feature engineering or domain-specific insights.\n",
      "\n",
      "4. **Potential Improvements**:  \n",
      "   - **Cross-Validation**: Ensure metrics are robust by using stratified k-fold validation.  \n",
      "   - **Class Imbalance**: If the dataset is imbalanced, consider techniques like SMOTE or class-weighted models.  \n",
      "   - **Ensemble Diversity**: Combine models (e.g., stacking) to leverage their strengths.\n",
      "\n",
      "---\n",
      "\n",
      "### **Recommendations**\n",
      "- **Deploy Gradient Boosting**: Based on its superior test performance, this model is ideal for production.  \n",
      "- **Monitor Overfitting**: Validate with a holdout test set to ensure the model generalizes well.  \n",
      "- **Interpret Feature Importance**: Use the AdaBoost feature plot to prioritize features for further analysis.  \n",
      "- **Experiment with Tuning**: Try adjusting `max_features` or `learning_rate` for Gradient Boosting to see if performance improves further.\n",
      "\n",
      "---\n",
      "\n",
      "### **Next Steps**\n",
      "1. **Deploy the Best Model**: Use the Gradient Boosting model for predictions.  \n",
      "2. **Evaluate Business Impact**: Align metrics (e.g., precision, recall) with business goals (e.g., minimizing false negatives).  \n",
      "3. **Monitor and Retrain**: Schedule periodic retraining with new data to maintain performance.  \n",
      "\n",
      "Let me know if you need help with visualizing the feature importances or further tuning! ðŸš€\n",
      "<think>\n",
      "Okay, let's see what the user is asking here. They provided a list of code snippets and outputs from various machine learning models, probably from a Jupyter notebook. The user might be looking for an analysis of these models' performance, hyperparameter tuning results, or perhaps an explanation of the code they've written.\n",
      "\n",
      "First, I need to parse through each code block and the corresponding outputs. Let me go step by step.\n",
      "\n",
      "The first code block mentions a Gradient Boosting Classifier with parameters like n_estimators=50, learning_rate=1.0, etc. The output here is the model's parameters, which might be part of hyperparameter tuning. Then there's a section where they check recall, precision, and accuracy on the test set for different models: dt2_tuned (Decision Tree), ada2_tuned (AdaBoost), and gboost2_tuned (Gradient Boosting). The outputs for these models would be the metrics on the test set.\n",
      "\n",
      "Looking at the outputs, the user might have run these models and want to compare their performance. They might also be interested in understanding which model performed best based on the metrics. For example, the Decision Tree model's test accuracy is 0.77, AdaBoost is 0.81, and Gradient Boosting is 0.82. The user might be looking for insights into why one model outperforms others or how to further optimize them.\n",
      "\n",
      "Additionally, there's a feature importance plot for AdaBoost, which could help in understanding which features are most influential. The user might want to know how to interpret these feature importances or how they can use this information for further model improvements.\n",
      "\n",
      "Another thing to note is the use of hyperparameter tuning with RandomizedSearchCV. The user might be interested in how the tuning process worked, which parameters were found to be optimal, and how those parameters affected the model's performance.\n",
      "\n",
      "Potential issues could include overfitting, especially if the training metrics are much higher than the test metrics. For example, if the training accuracy is significantly higher than the test accuracy, that might indicate overfitting. However, the provided outputs don't include training metrics, so I can't assess that without more data.\n",
      "\n",
      "The user might also be looking for recommendations on which model to deploy based on the test metrics. Since Gradient Boosting has the highest accuracy and precision, it might be the preferred model. However, they should also consider other factors like computational resources, interpretability, and business requirements.\n",
      "\n",
      "I should also check if the user has any specific questions about the code, the results, or the models. Since they didn't ask a direct question, maybe they want a summary of the findings or an explanation of the models' performance. Alternatively, they might need help with next steps, like further tuning or deploying the model.\n",
      "\n",
      "In summary, the user's request is to analyze the provided code and outputs to understand the model performance, hyperparameter tuning results, and possibly recommendations for model selection or improvement. I'll need to present a clear analysis of each model's metrics, discuss the hyperparameter tuning process, and offer insights into the feature importances and potential next steps.\n",
      "</think>\n",
      "\n",
      "### **Analysis of Model Performance and Hyperparameter Tuning**\n",
      "\n",
      "Here's a breakdown of the models, their hyperparameters, and performance metrics based on the provided code and outputs:\n",
      "\n",
      "---\n",
      "\n",
      "### **1. Decision Tree (dt2_tuned)**\n",
      "- **Hyperparameters**:  \n",
      "  - `max_depth=3` (from earlier tuning)  \n",
      "  - Other parameters were not explicitly shown, but the final model was tuned using `RandomizedSearchCV`.  \n",
      "- **Test Metrics**:  \n",
      "  - **Recall**: ~0.77  \n",
      "  - **Precision**: ~0.78  \n",
      "  - **Accuracy**: ~0.77  \n",
      "- **Observation**:  \n",
      "  - The model performs reasonably but isn't the top performer. It may benefit from further tuning (e.g., adjusting `max_depth` or using ensemble methods).\n",
      "\n",
      "---\n",
      "\n",
      "### **2. AdaBoost (ada2_tuned)**\n",
      "- **Hyperparameters**:  \n",
      "  - `n_estimators=300`, `learning_rate=1.0`, `estimator=DecisionTreeClassifier(max_depth=3)`, `algorithm='SAMME'`  \n",
      "- **Test Metrics**:  \n",
      "  - **Recall**: ~0.81  \n",
      "  - **Precision**: ~0.83  \n",
      "  - **Accuracy**: ~0.81  \n",
      "- **Observation**:  \n",
      "  - AdaBoost achieves strong performance, especially with high precision. The choice of `SAMME` algorithm and deeper trees (`max_depth=3`) likely contributed to better generalization.  \n",
      "  - Feature importances (from the plot) could help identify key predictors.\n",
      "\n",
      "---\n",
      "\n",
      "### **3. Gradient Boosting (gboost2_tuned)**\n",
      "- **Hyperparameters**:  \n",
      "  - `n_estimators=50`, `learning_rate=1.0`, `max_depth=5`, `min_samples_split=20`, `min_samples_leaf=2`, `max_features=0.1`, `loss='log_loss'`  \n",
      "- **Test Metrics**:  \n",
      "  - **Recall**: ~0.82  \n",
      "  - **Precision**: ~0.84  \n",
      "  - **Accuracy**: ~0.82  \n",
      "- **Observation**:  \n",
      "  - The Gradient Boosting model outperforms the others, achieving the highest accuracy and precision. The combination of `max_depth=5` and `learning_rate=1.0` suggests a balance between model complexity and convergence.  \n",
      "  - The `max_features=0.1` parameter indicates a focus on reducing overfitting by limiting feature usage per tree.\n",
      "\n",
      "---\n",
      "\n",
      "### **Key Insights**\n",
      "1. **Model Comparison**:  \n",
      "   - **Gradient Boosting** is the top performer, followed by **AdaBoost**, then **Decision Trees**.  \n",
      "   - Gradient Boosting's high precision and recall suggest it's best suited for this dataset, especially if the goal is to minimize false negatives (e.g., in fraud detection or medical diagnosis).\n",
      "\n",
      "2. **Hyperparameter Tuning**:  \n",
      "   - All models were tuned using `RandomizedSearchCV`, which efficiently explores the parameter space.  \n",
      "   - Gradient Boosting's optimal parameters (e.g., `max_depth=5`, `learning_rate=1.0`) likely reflect a trade-off between model complexity and training speed.\n",
      "\n",
      "3. **Feature Importance**:  \n",
      "   - The AdaBoost model's feature importance plot (not shown here) would highlight the most impactful predictors. This could guide feature engineering or domain-specific insights.\n",
      "\n",
      "4. **Potential Improvements**:  \n",
      "   - **Cross-Validation**: Ensure metrics are robust by using stratified k-fold validation.  \n",
      "   - **Class Imbalance**: If the dataset is imbalanced, consider techniques like SMOTE or class-weighted models.  \n",
      "   - **Ensemble Diversity**: Combine models (e.g., stacking) to leverage their strengths.\n",
      "\n",
      "---\n",
      "\n",
      "### **Recommendations**\n",
      "- **Deploy Gradient Boosting**: Based on its superior test performance, this model is ideal for production.  \n",
      "- **Monitor Overfitting**: Validate with a holdout test set to ensure the model generalizes well.  \n",
      "- **Interpret Feature Importance**: Use the AdaBoost feature plot to prioritize features for further analysis.  \n",
      "- **Experiment with Tuning**: Try adjusting `max_features` or `learning_rate` for Gradient Boosting to see if performance improves further.\n",
      "\n",
      "---\n",
      "\n",
      "### **Next Steps**\n",
      "1. **Deploy the Best Model**: Use the Gradient Boosting model for predictions.  \n",
      "2. **Evaluate Business Impact**: Align metrics (e.g., precision, recall) with business goals (e.g., minimizing false negatives).  \n",
      "3. **Monitor and Retrain**: Schedule periodic retraining with new data to maintain performance.  \n",
      "\n",
      "Let me know if you need help with visualizing the feature importances or further tuning! ðŸš€\n"
     ]
    }
   ],
   "source": [
    "response: ChatResponse = chat(model='qwen3', messages=[\n",
    "  {\n",
    "    'role': 'user',\n",
    "    'content': prompt,\n",
    "  },\n",
    "])\n",
    "print(response['message']['content'])\n",
    "# or access fields directly from the response object\n",
    "print(response.message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a4e9b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
